

--- Messages from #announcements ---
Happy Birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday::sparkles::bouquet:
Happy birthday <@U08CN8XSF5X> and <@U08C2VADVPG> :partying_face:
Happy birthday <@U08CN8XSF5X> and <@U08C2VADVPG>   :sparkles::partying_face:
Happy birthday <@U08C2VADVPG> &amp; <@U08CN8XSF5X> :birthday::tada::confetti_ball:
Happy Birthday, <@U08CN8XSF5X> <@U08C2VADVPG> ! We hope your special day is as great as you are!:tada::confetti_ball::sparkles::dizzy:
Happy Birthday <@U08C2VADVPG> and <@U08CN8XSF5X>:sparkles:
Happy Birthday <@U08C2VADVPG> &amp; <@U08CN8XSF5X> :birthday::bouquet:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X>! :sparkles::birthday:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X>:sparkles::birthday:
Happy Birthday <@U08C2VADVPG> and <@U08CN8XSF5X>!!! :birthday::sparkles::fire:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X>! :sparkles::birthday:
Happy Birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday::sparkles::bouquet:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday::bouquet:
Wishing a very happy birthday to <@U08C2VADVPG> and <@U08CN8XSF5X>! :sparkles::birthday:
Wishing a very happy birthday to <@U08C2VADVPG> and <@U08CN8XSF5X>! :sparkles::birthday:
Happy birthday <@U08C2VADVPG> &amp; <@U08CN8XSF5X> :birthday::tada::confetti_ball:
Happiest birthday <@U08CN8XSF5X> and <@U08C2VADVPG> :tada::bouquet::birthday:
Wishing a very happy birthday to <@U08C2VADVPG> and <@U08CN8XSF5X>! :sparkles::birthday:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday::sparkles:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday::confetti_ball:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday:
Wish you a very Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday: :bouquet: 
Happy birthday <@U08CN8XSF5X> and <@U08C2VADVPG> :tada:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday::bouquet:
Wishing a very happy birthday to <@U08C2VADVPG> and <@U08CN8XSF5X>! :sparkles::birthday:
Happy Birthday <@U08C2VADVPG> &amp; <@U08CN8XSF5X>:confetti_ball::partying_face:
Wishing a very happy birthday to <@U08C2VADVPG> and <@U08CN8XSF5X>:sparkles: :tada:
Wish you a very happy birthday <@U08CN8XSF5X> and <@U08C2VADVPG> :birthday:
Happy Birthday <@U08C2VADVPG> &amp; <@U08CN8XSF5X> :birthday::bouquet:
Happiest Birthday <@U08CN8XSF5X> &amp; <@U08C2VADVPG> :sparkles::birthday:
Happy birthday <@U08C2VADVPG> and <@U08CN8XSF5X> :birthday::bouquet:
Wishing a very happy birthday to <@U08C2VADVPG> and <@U08CN8XSF5X>:sparkles: :tada:
Wishing a very happy birthday to <@U08C2VADVPG> and <@U08CN8XSF5X>! :sparkles::birthday:
Happiest birthday <@U08C2VADVPG> &amp; <@U08CN8XSF5X>  :confetti_ball::birthday:
Dear <@U08C2VADVPG> & <@U08CN8XSF5X> :tada::birthday: *Happy Birthday!* :birthday::tada:Wishing you a day filled with love, laughter, and endless joy! :blush::star2:
 May all your dreams come true and this new year bring you lots of success, happiness, and beautiful memories. :balloon::gift::sparkling_heart: Stay blessed, keep smiling, and keep shining bright like a star! :sparkles::cherry_blossom: Have a fantastic and unforgettable celebration! :confetti_ball::cake::tada:

Best Wishes!!
Restarted
<!here> restarting 44.213.44.23 on datopic AWS account, who so ever would be impacted please coordinate with your leads to restart the respective services
I’m really grateful for your thoughtful birthday wishes :pray::skin-tone-3:
Thank you for making me feel so loved :heart:
Happy birthday <@U03QJGR9G8G> Sir:bouquet::birthday:
Happy birthday <@U03QJGR9G8G> sir :birthday::tada:
Happy Birthday <@U03QJGR9G8G> sir :birthday::confetti_ball:
Happy Birthday <@U03QJGR9G8G> Sir :birthday::sparkles:
Happy Birthday <@U03QJGR9G8G> sir :confetti_ball::birthday:
Happy Birthday <@U03QJGR9G8G> Sir :birthday::sparkles:
Happy birthday <@U03QJGR9G8G> sir :birthday::tada:
Happiest Birthday <@U03QJGR9G8G> Sir :bouquet::birthday:
Happy birthday <@U03QJGR9G8G> sir :birthday::tada::bouquet:
Happy birthday <@U03QJGR9G8G> sir :birthday::tada:
Happiest Birthday <@U03QJGR9G8G> Sir :bouquet::birthday:


--- Messages from #leavesannouncements ---
Hi Team
<@U089C3M07TQ> is on sick leave for 2 days.
Hi Team
<@U08CN95GY2D> is on sick leave today.
Hi team 
<@U04RTNRTJ30> is on planned leave today
Thanks
Hey team
I am on sick leave today 
Thanks
hi team,
<@U08C6P11F2R> is on emergency leave
Thanks
Hi team,
<@U08CN8XSF5X> is on sick leave today.
Hi,
Ritanshu is on Sick leave today.
hi team,
<@U08BU6SMZAP> is on sick leave today
Hi Team
Varsha and Ritesh are on planned leave today.
Thanks
Hey, 
I am on planned leave today.

Thanks.
Hi Team
Shekhar is on planned leave today.
Thanks
Hi Team,
<@U01U094T3K5> sir is on sick leave today.
Hey team,
<@U08CN8XSF5X> is on 2 days planned leave.
Thanks
Hey team,
<@U04H68D37B4> is on 3 days planned leave.
Hey team
Prerna is on sick leave today
Thanks
Hi
I am on sick leave today.
Thanks
Hi Team
<@U08C6P11F2R> is on sick leave today.
Thanks
Hey team
Abhishek is on planned leave
Thanks
Hi team
<@U06H48PHUN9> is on sick leave today
Thanks!
Hi team 
I’m on planned leave today.
Thanks
Good morning team, I'm on leave today. Thanks!
Hii
Tanisha is on 3 days Planned leaves
Thanks.
Hey team
Rutvi is on sick leave today 
Thanks
Hi Team
Vasundhara is on sick leave today.
Thanks
Hi Team
<@UTWBT9H8D> sir is on planned leave today.
Thanks
All leaders, please let me know explicitly about your team members's unplanned leaves notification you receive in the morning. <@U03FQTNG9DH> please prepare a list of all such leaves with the reason separately.
Ok
Yes, <@UF9AJRRU6> sir, he mentioned during the sprint planning that he would be taking leave either on the last Friday or today (Monday).
<@UV2T5GT99> is Akash on planned leave
hi team
<@U08BU6SMZAP>
is on planned leave today for his project presentation
Hi team 
<@U05C1MVRH5Z> is on leave today.
Thanks 
Hi,
Sandeep is on planned leave today.
Thanks
Hey team
Prerna is on sick leave today
Thanks
Hey team
Aman is on second half leave due to medical emrgency
Thanks
Hi Team,
I'm on sick leave for today
Thanks
Hi team 
<@U06H48PHUN9> is on emergency leave today
Thanks
<@U06H9HPP736> is on sick leave today
Hi Team
<@U08CN95GY2D> and <@U08CC4934BE> are on exam leave from 7th-11th April.
Hi team
<@U06T9NREQDC> is on Sick leave today.
Thanks
Hi 
Today i am on planned leave.
Hi team
<@U06HTP8MCRL> is on leave today.
Thanks
Hi team
I'm on planned leave today.
Thanks
Hi team
<@U052MGX0A1W> is on sick leave today.
Thanks
Hi team
<@U05C1MVRH5Z> is on sick leave today.
Thanks
Hello Team, I am on planned leave today and on 11th April. Thanks 
 hi team 
<@U06HTP8MCRL> is on planned leave for 2 days.
Hi
I am on sick leave today
Thanks
Hi Team,
<@U07KU4R7GQ2> is on sick leave today.
Thanks
Hi team
<@U059KQY2UAK> is on sick leave today.
Thanks
Hi Team
<@U06J0CM3NR0> is on sick leave today.
Thanks


--- Messages from #dol-datopic-mails ---
archived the channel
ok, thanks, let me check
<@UF8TCND39> Sir, Not receiving the jira ticket status update notification over here from February. Thanks
<@U06U5L6UAD6> has joined the channel
<@U04NARS71G9> has joined the channel
<@U06P73Q23GV> has joined the channel
acked

Ack

Ack

Ack

Ack

Ack

Ack

Ack

acked

Acked

acked

acked

Acked

Ack

Ack

Ack

Ack

Ack

Ack

Ack

Acked

acked



--- Messages from #dtp-daily-office-presence ---
archived the channel

This message contains interactive elements.
<!here>
@here pls send me your thoughts in gdrive xls and dont spend more than 20 mins in xls building. Share 1-1 sheet with me by 5pm.
Thanks <!here>. This Friday - open basic knowledge puzzle is out on floor; Preferred time limit is *1hr*, best is *30 mins*. Pre-requisite is db knowledge.
Those who have missed to catch. pls ping me 1-1.
*Note - client work is prioiry. :)*
yes sir:grin:
Do we have such rule...i didnt know
Sir Because we do parties only on Wednesdays and Fridays
Why wednesday...
<@UF8TCND39> <@U04H68D12EN> it will be on upcoming wednesday:star-struck::zany_face:
<@UF8TCND39> sir month end party?
:innocent:
<@UTWBT9H8D> <@UV2T5GT99> thank you for July month.   :)
Let's party :partying_face::partying_face:
Waiting for the team to unbox:sweat_smile:
Thanks everyone who joined and celebrated together


Pls enjoy, call has started for us :slightly_smiling_face:
Guys please come fast. Treat is ready
Thank you <@UF8TCND39> sir for considering us
many engineers are on exam leave, can we pls do after holi or next week
<!here> Any plans for month end party today :sweat_smile:

Hi guys
Its party time, please come downstairs.
only 12 means No party?
agree:+1:
:+1:
agree:+1:
:+1:
<@U04MQRR144W> has joined the channel
<@UF9AJRRU6> no sir
5 messages and 10 reactions
Agree
Only 5 …means no party?
Agree:+1:
Agree :+1:
Agree :+1:
Agree :+1:
Agree:+1::skin-tone-2::+1::skin-tone-2::+1::skin-tone-2::+1::skin-tone-2::+1::skin-tone-2:
Voting for party today
Agree :+1: disagree :-1:
Excellent, pls plan for tomorrow Friday, hope works for everyone
I am in
<@UF8TCND39> Sir <@UF9AJRRU6> Sir Any plans for party?
<@U04HVUVP5CG> has joined the channel
<@U04HJT1101F> has joined the channel
<@U04H68D37B4> has joined the channel
<@U04H8MTEZM2> has joined the channel
<@U04HJT1B5EV> has joined the channel
<@U04H68D12EN> has joined the channel


--- Messages from #assistme ---
<!here> Hi everyone,
I am working on transferring resources from one account to other on AWS. As I already have created a new account this month, I am in need of one for testing the task output. If someone has an AWS account please share. I assure that no billing would be generated.
Thanks.
<@UTWBT9H8D> sir getting 502 bad gateway error in people pulse
8 hrs is showing due to your cache data stored by browser
after reload the page it is working fine
Showing 8 hrs at the time of check-in please check may be after refreshing the page it will work fine. <@UTWBT9H8D> <@U03NQMRLY87>
<!here> Facing this issue while setting up os in vm.
<!here>
hello guys

As we want to take our cyber security mesh live on git-hub, I am looking for suggestions/input regarding:
• is it possible to migrate history of Bit-bucket to git-hub?
if anyone is having any idea to complete this process then please post here
Hi Team <!here>,
I am working on setting up pq-openvpn and encountering an issue when trying to establish a connection between the client and server. Both the server and client appear to be running successfully based on the configuration files provided below, but the client is unable to connect to the server.
If anyone can assist with diagnosing and resolving this issue, please ping me, and I will provide further details as needed.
Thank you!
Config files for server and client are as below :
Hi everyone,
I am unable to install any command like as yum install gcc, cmake, make for rhel 7.
if anyone knows how to install these commands for rhel 7 then please try to connect 1-1.
note : this is aws eks cluster so I do not have any access to admin.conf
hi <!here>
guys I am working on kubernetes cluster deployment and facing issue in accessing cluster info using cloud cli / local system
*error: You must be logged in to the server (Unauthorized)*

i have already provided all required roles to iam user i.e admin and eks policy , etc.  Apart from it already tried solutions from stackover flow , chatgpt, awsrepost,serverfault , etc.
but again and again same error.

if anyone had already done this type of work or can help me , then please try to reachout to me.
it's urgent and important.
hi guys <!here>
if anyone knows how to connect eksctl with your existing eks cluster present on cloud,
then please try to connect 1-1 or share any doc if you have.

current scenario, I know how to create and manage fresh cluster from eksctl i.e from local to cloud, but do not know how to connect  it with existing one present over cloud.
:innocent:

<!here>
Hey all,
I am working on connecting to Document DB without installing mongo on EC2, either
1. Programmatically using the mongo shell when TLS is enabled, or
2. Using EC2 host to connect to DocumentDB cluster from the local system (ssh tunneling)
I have tried both methods and they are giving the same error of *MongoServerSelectionError: Server selection timed out after 30000 ms*

Tried by following the given documentations:
<https://docs.aws.amazon.com/documentdb/latest/developerguide/connect_programmatically.html>
<https://docs.aws.amazon.com/documentdb/latest/developerguide/connect-from-outside-a-vpc.html>

I have made relevant changes in the security group rules, Network ACLs and Route tables in which the DocumentDB cluster resides to allow traffic in and out of it. Still encountering the same problem of Connection timed out.

If anyone has any idea or worked over it, please connect with me 1-1. Thank you.
<!here> 
Guys I was working with kubeadm and minukube
Suddenly I have lost access to any web related services:slightly_frowning_face: and saying invalid certificate 
Can anyone please let me know if he/she had faced this already and knows any solution ??
<@UV2T5GT99> any good reason of not conducting technical sessions for last 4 weeks.
sorry, not aware of it.
My concern is the code we use in our projects, like in smart contract we detect vulnerabilities of the contract but the code we use has vulnerability or not?
Yes we check it for smart contracts
Hey team
Do we check vulnerabilities in our projects, if yes please share tools that we use to achieve it
Here is the Dockerfile being used:

Hey everyone,
I have been working on Kubernetes deployment for Smalter frontend. There is an issue in the Dockerfile and docker-compose file for the container creation of the modules of the application.

I have tried to solve the error, by first building the node modules and then by copying all source files into the nginx server in the container. The given method was not working.

Thereafter with some help the docker-compose file with the Dockerfile gave results in the localsystem by creating containers. But this gave errors in the container as they were not executable. The Kubernetes pods gave this error.

Error:
kubectl logs front1-deployment-69c6f96cff-tt674
Defaulted container "smalter-mod-1" out of: smalter-mod-1, smalter-mod-2, smalter-bo
npm error Missing script: "start"
npm error
npm error Did you mean one of these?
npm error   npm star # Mark your favorite packages
npm error   npm stars # View packages marked as favorites
npm error
npm error To see a list of scripts, run:
npm error   npm run

npm error A complete log of this run can be found in: /root/.npm/_logs/2024-06-25T06_56_28_244Z-debug-0.log





Any change to this was not giving results.
Please help in any way possible. Thank you
Anyone already know or is facing issue with chrome opening issue. Like Chrome was working fine, and one fine day, you click on chrome icon, and it does not open and no splash or action happens/no response by OS.

Or you hit from terminal to open it and it gives error similar to below.

_ERROR:<http://process_singleton_posix.cc|process_singleton_posix.cc>(353)] The profile appears to be in use by another Google Chrome process (3471) on another computer (dtp2024u06005-Latitude-3410). Chrome has locked the profile so that it doesn't get corrupted. If you are sure no other processes are using this profile, you can unlock the profile and relaunch Chrome_

Kindly contact me 1-1.
Project(Build Name)_Environment(if apply)_YYYYMMDD_V1.0/commit-id(Version)
lets connect 1 on 1
ok, this is for production or release type
but i do not have version, i want to manage these for ongoing development
if releasing with major change increment version in number else in decimal places.
Hi, Project(Build Name)_Environment(if apply)_YYYYMMDD_V1.0(Version)
Hope it helps.
Hi <!here>,
I need your suggestions regarding the naming of app/binary/exe files created after building our code. After making upgrades or changes to the code, I have to build it, resulting in a new app file.
How do you manage the naming of these files? Do you include the commit ID in the name, or do you use a simpler naming convention?

Thanks in advance for your input!!
hi <!here>
i need help regarding windows installer using *install forge*

I have created a windows installer and it is working fine, currently i have to export environment path manually, but I want it to be done automatically as soon as installer finished its work on windows.

Already I have a suggestion to use batch script, but there is no option to use it in install forge while creating installer.
<!here> I  am encountering difficulties importing a single Bitbucket repository to GitLab, as depicted in the attached screenshot. Your assistance in resolving this issue would be greatly appreciated!
<!here> please join the session:
<https://meet.google.com/rmq-ichz-svx>
<https://meet.google.com/jmc-mnhe-qvb|https://meet.google.com/jmc-mnhe-qvb>
```<http://explorer.mynetwork.com|explorer.mynetwork.com>      | [2024-05-07T07:07:01.567] [ERROR] FabricGateway - Failed to create wallet, please check the configuration, and valid file paths: {
<http://explorer.mynetwork.com|explorer.mynetwork.com>      |   "errno": -2,
<http://explorer.mynetwork.com|explorer.mynetwork.com>      |   "code": "ENOENT",
<http://explorer.mynetwork.com|explorer.mynetwork.com>      |   "syscall": "open",
<http://explorer.mynetwork.com|explorer.mynetwork.com>      |   "path": "organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt"
<http://explorer.mynetwork.com|explorer.mynetwork.com>      | }
<http://explorer.mynetwork.com|explorer.mynetwork.com>      | [2024-05-07T07:07:01.568] [ERROR] FabricClient - ExplorerError {
<http://explorer.mynetwork.com|explorer.mynetwork.com>      |   name: 'ExplorerError',
<http://explorer.mynetwork.com|explorer.mynetwork.com>      |   message: '[\n' +
<http://explorer.mynetwork.com|explorer.mynetwork.com>      |     "  'Failed to create wallet, please check the configuration, and valid file paths'\n" +
<http://explorer.mynetwork.com|explorer.mynetwork.com>      |     ']'
<http://explorer.mynetwork.com|explorer.mynetwork.com>      | }```
Pls paste the exact error here
<!here> Need help resolving this wallet issue while integrating hyperledger explorer with hyperledger network.
I've tried both absolute and relative path for the pem file, didn't work.
<https://meet.google.com/vui-uypg-rmm>
<@U05BM9QMQDV> Please share invite of meeting here as well.
<!here> do we have anyone who has hands on on Rust
<!here> can anyone help me to resolve this issue, I'm getting this error while opening the machine
done no worries!!
path -&gt;   /home/dte147/Documents/hybrid-pqc/build/lib

`dte147@dte147-Latitude-5520:~/go-naoris-dposec$ ls -lrt /home/dte147/Documents/hybrid-pqc/build/lib`
`total 40296`
`-rwxrwxr-x 1 dte147 dte147   166112 Apr 10 16:55 libhybridpqc.so.0.0.1-dev`
`lrwxrwxrwx 1 dte147 dte147       25 Apr 10 16:55 libhybridpqc.so.2 -&gt; libhybridpqc.so.0.0.1-dev`
`lrwxrwxrwx 1 dte147 dte147       17 Apr 10 16:55 libhybridpqc.so -&gt; libhybridpqc.so.2`
<@U04H68D12EN> have you created the symbolic link? If yes share the path of the symbolic link
hi <!here>
i am stuck with "*Symbolic Links in linux*"


`dte147@dte147-Latitude-5520:~/go-naoris-dposec$ ./build/bin/geth -h`
`./build/bin/geth: symbol lookup error: ./build/bin/geth: undefined symbol: crypto_sign_dilithium_ed25519_sphincs_keypair`

Any help would be valuable and appreciated!!
<!here>
Hello everyone,
please join my session at 4:00 pm about Basic Cryptosystem
Thursday, March 21 · 4:00 – 4:30pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/fbh-ixdj-vju>
ok, will share on it, thanks
Sir, As of now, details related to QA automation and selenium are getting shared in <#C03N597989Z|>
<!here> any active channel on QA automation or selenium ?


--- Messages from #dtp-it-support ---
Dear <@U02SP005MRS> Sir, my laptop's trackpad is not working, and it's also crashing repeatedly. Kindly help me with this issue.
Ok <@U08CN8XSF5X>
<@U02SP005MRS> sir My laptop is taking a long time to process and isn't functioning correctly .  and hangs out, so I have to restart it a lot to get it to work properly. Can you please check into this issue
<@U02SP005MRS>
<@U03NQMRLY87> ok
Hi
<@U02SP005MRS> Please help Harsh as his system in not booting.
<@U08C2VABT1C> kindly share screenshot here and try to reinstall OS.
Thanks
<@U02SP005MRS> sir , my laptop's mic is not working properly so please look into this issue.
Ok <@U06HXEY3NVB>
<@U02SP005MRS> sir, my laptop charger is not working properly. Frequently disconnects and connects from system. Please look into the issue sir.
Thanks for the timely support
<@U03NQMRLY87> ok Sir
<@U02SP005MRS>, please prioritise checking if we can arrange a spare one for <@U08C2VABT1C>. Thanks.
<@U02SP005MRS> sir my laptop is continuously going on this mode due to which I am unable to work. Please look into this matter.
ok <@U06HTP8NHRC>
Hi <@U02SP005MRS> sir,
*Reminder* about the *damaged laptop charger*—it’s still disconnecting frequently and *causing loss of work*. Requesting a quick replacement or repair.
Thanks!
I am unable to work due to network issues in Mohali office <@U02SP005MRS>
OK <@U08CN8XSF5X> let me check
<@U02SP005MRS> sir i am experiencing an issue with my laptop cursor. its not working properly , it stop working many times and clicking on things i don't clicked . i restarted laptop many times but after some time things get the same
Ok <@U06HXEY3NVB> <@U06HTP8NHRC>
<@U02SP005MRS> sir, I am experiencing an issue with my laptop charger. The charging cable appears to be damaged, causing frequent disconnections while charging. The charger intermittently connects and disconnects, making it difficult to keep my laptop powered properly.
Could you please assist me in getting a replacement or repairing the charger at the earliest convenience?
<@U02SP005MRS> sir, my laptop is getting stuck a lot. I have restarted my laptop many times now.
<@U02SP005MRS> We are facing network issue in 202.
<@U02SP005MRS> sir wifi is not working in 222
<@U02SP005MRS> sir, issues with my machine
• My machine is not working properly it's lagging all the time. Even when the load average is below 2. 
• Battery capacity is at 33%. 
• It constantly get disconnected from the charger even when the charger is plugged.
Please look into this
Thanks
<@U02SP005MRS> sir my system is getting stuck continuously always need to restart , terminal and browser not open many time also my battery life is low always need to plugin in the charger   

Please have a look into this matter.
OK <@U04HVUVP5CG>
<@U02SP005MRS> sir please increase RAM of my system , facing system performance issues.
ok <@UV2T5GT99>
<@U02SP005MRS>, could you please confirm which network we should connect to in cabin 202? We are experiencing internet issues.
<@U06LE3VCR7Y> ok
Hi <@U02SP005MRS>
My system is getting stuck continuously since last month The code editor is also not responding because of that I am loosing my work as I need to restart my system forcefully

Hi <@U02SP005MRS> and <@U03NQMRLY87> sir , my system is flickering frequently. Please suggest something
<@U02SP005MRS> Sir, my laptop's charging port is not working
Hi <@U02SP005MRS>, MacBook charger isn’t working. Please check the attachment.
Hi <@U02SP005MRS> good morning!
MacBook screen shut off again while flickering. Please have a look…
Thanks
<@U06SBF6UT33> ok
<@U02SP005MRS> sir frequently facing screen flickering issues, please look into this
Ok <@U059KQY2UAK> I call you
<@U02SP005MRS> sir my machines battery backup is too low. It's not even getting fully charged and in 5 minutes it's getting shutdown. Please look into this
Thanks
Ok <@U04H68D12EN>
<@U02SP005MRS> sir
facing issue with internet speed
<@U04AVJZBWBA> ok let me check
Hi <@U02SP005MRS> sir,
My system facing error, pls look into this issue
<@U06HTP8NHRC> ok i will talk to Sir
<@U02SP005MRS> sir, the battery health of my laptop is *6.12 %*
Hii <@U02SP005MRS> sir,
I'm facing an issue with my laptop's battery. It behaves erratically, dropping drastically from a full charge to shutting down within 15 minutes. This forces me to plug in the charger constantly, which is quite inconvenient.
Could you please assist in diagnosing and resolving this issue at the earliest? Let me know if you need any specific details.
Hi <@U02SP005MRS> 
My system is getting stuck continuously since last month The code editor is also not responding because of that I am loosing my work as I need to restart my system forcefully
<@U04HJT1B5EV> <@U06HXEY3NVB> ok
<@U02SP005MRS> sir, my system is getting stuck constantly. Slack, Chrome and Terminal is not able to work and I have to wait for system to respond again. Please look into this sir.


--- Messages from #sca-pager-duty-notification ---
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Hello naoris test message!
```
```
Resume uploaded success.
```
```
Resume uploaded success.
```
```
Resume uploaded success.
```
Ack
```
testing
```
Ack
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/TROLL.sol_1716772519_deep/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/TROLL.sol_1716772519_deep/TROLL.sol|TROLL.sol>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-27 01:15:03.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/TROLL.sol_1716772519_deep/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/TROLL.sol_1716772519_deep/TROLL.sol|TROLL.sol>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-27 01:15:03.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xefca7D92B17372Ce2019343FF0203C4f48eaD04A_1716772416_deep/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xefca7D92B17372Ce2019343FF0203C4f48eaD04A_1716772416_deep/PONKE.zip|PONKE>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-27 01:13:21.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xefca7D92B17372Ce2019343FF0203C4f48eaD04A_1716772416_deep/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xefca7D92B17372Ce2019343FF0203C4f48eaD04A_1716772416_deep/PONKE.zip|PONKE>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-27 01:13:21.
```
```
The audit report for TROLL.sol, based on the regex pattern, has been successfully generated.
```
```
The audit report for PONKE.zip, based on the regex pattern, has been successfully generated.
```
Ack
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/TROLL.sol_1716772519_deep/TROLL.sol|TROLL.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_TempFiles/1716772503_TROLL.sol|TROLL.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xefca7D92B17372Ce2019343FF0203C4f48eaD04A_1716772416_deep/PONKE.zip|PONKE.zip>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
Ack
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/developingWallet.sol_1716714625_quick/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/developingWallet.sol_1716714625_quick/developingWallet.sol|developingWallet.sol>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-26 09:07:17.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/developingWallet.sol_1716714625_quick/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/developingWallet.sol_1716714625_quick/developingWallet.sol|developingWallet.sol>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-26 09:07:17.
```
Ack
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xB9A0b04aBFA514966F0156EC42283852f7520061_1716714371_quick/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xB9A0b04aBFA514966F0156EC42283852f7520061_1716714371_quick/Crowdfunding.sol|Crowdfunding>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-26 09:05:54.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xB9A0b04aBFA514966F0156EC42283852f7520061_1716714371_quick/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xB9A0b04aBFA514966F0156EC42283852f7520061_1716714371_quick/Crowdfunding.sol|Crowdfunding>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-26 09:05:54.
```
Ack
```
The audit report for developingWallet.sol, based on the regex pattern, has been successfully generated.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/developingWallet.sol_1716714625_quick/developingWallet.sol|developingWallet.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
The audit report for Crowdfunding.sol, based on the regex pattern, has been successfully generated.
```
Ack
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_TempFiles/1716714437_developingWallet.sol|developingWallet.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0xB9A0b04aBFA514966F0156EC42283852f7520061_1716714371_quick/Crowdfunding.sol|Crowdfunding.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
Ack
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/NOADsPool.sol_1716685347_deep/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/NOADsPool.sol_1716685347_deep/NOADsPool.sol|NOADsPool.sol>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-26 01:02:11.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/NOADsPool.sol_1716685347_deep/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/NOADsPool.sol_1716685347_deep/NOADsPool.sol|NOADsPool.sol>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-26 01:02:11.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0x5e8655a76675fd92793E2F3Ad9E62418A5bca5FD_1716685303_deep/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0x5e8655a76675fd92793E2F3Ad9E62418A5bca5FD_1716685303_deep/BoostedPendleStrategy.zip|BoostedPendleStrategy>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2024-05-26 01:01:27.
```
```
The audit report for NOADsPool.sol, based on the regex pattern, has been successfully generated.
```
```
The audit report for BoostedPendleStrategy.zip, based on the regex pattern, has been successfully generated.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/NOADsPool.sol_1716685347_deep/NOADsPool.sol|NOADsPool.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_TempFiles/1716685331_NOADsPool.sol|NOADsPool.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports_Dev/0x5e8655a76675fd92793E2F3Ad9E62418A5bca5FD_1716685303_deep/BoostedPendleStrategy.zip|BoostedPendleStrategy.zip>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
Ack


--- Messages from #sca-pager-duty-notification-staging ---
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/NaorisToken.sol_1744286578_deep/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/NaorisToken.sol_1744286578_deep/NaorisToken.sol|NaorisToken.sol>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2025-04-10 12:02:37.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/NaorisToken.sol_1744286578_deep/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/NaorisToken.sol_1744286578_deep/NaorisToken.sol|NaorisToken.sol>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2025-04-10 12:02:37.
```
Reminder: Follow up <!here> on sca-daily pending report status.
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/NaorisToken.sol_1744286578_deep/NaorisToken.sol|NaorisToken.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_TempFiles/1744286557_NaorisToken.sol|NaorisToken.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0xf800f235Ab2E29b82dA807Fadeb63Db30359196e_1744285017_quick/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0xf800f235Ab2E29b82dA807Fadeb63Db30359196e_1744285017_quick/ProxyGroupWallet.sol|ProxyGroupWallet>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2025-04-10 11:35:38.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0xf800f235Ab2E29b82dA807Fadeb63Db30359196e_1744285017_quick/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0xf800f235Ab2E29b82dA807Fadeb63Db30359196e_1744285017_quick/ProxyGroupWallet.sol|ProxyGroupWallet>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2025-04-10 11:35:38.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x6D6B7D1Db521Df9a1763B2516eb8b04560DEE073_1744284786_quick/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x6D6B7D1Db521Df9a1763B2516eb8b04560DEE073_1744284786_quick/MultiSigCloneFactory.zip|MultiSigCloneFactory>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2025-04-10 11:32:48.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x6D6B7D1Db521Df9a1763B2516eb8b04560DEE073_1744284786_quick/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x6D6B7D1Db521Df9a1763B2516eb8b04560DEE073_1744284786_quick/MultiSigCloneFactory.zip|MultiSigCloneFactory>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2025-04-10 11:32:48.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0xf800f235Ab2E29b82dA807Fadeb63Db30359196e_1744285017_quick/ProxyGroupWallet.sol|ProxyGroupWallet.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x6D6B7D1Db521Df9a1763B2516eb8b04560DEE073_1744284786_quick/MultiSigCloneFactory.zip|MultiSigCloneFactory.zip>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
An error occured while uploading single smart contractSequelizeDatabaseError: invalid input syntax for type integer: "$ID"
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x3Ba40e5275ff828e3bA857e74f593e1E5d51eb21_1744284698_invalid/HypeDetector.sol|HypeDetector.sol>' - uploaded by: <mailto:admin@naoris.com|admin@naoris.com>.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x8B1C53942dDa1403e954594985C007ADdCa6c18c_1744272838_quick/intermediateReport.zip|automated report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x8B1C53942dDa1403e954594985C007ADdCa6c18c_1744272838_quick/TrustedRelayerIsm.zip|TrustedRelayerIsm>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2025-04-10 08:13:38.
```
```
The '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x8B1C53942dDa1403e954594985C007ADdCa6c18c_1744272838_quick/intermediateReport.zip|intermediate report>' has been generated for '<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x8B1C53942dDa1403e954594985C007ADdCa6c18c_1744272838_quick/TrustedRelayerIsm.zip|TrustedRelayerIsm>' and is currently under review. It was uploaded by <mailto:psingh@datopic.com|psingh@datopic.com> on 2025-04-10 08:13:38.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x8B1C53942dDa1403e954594985C007ADdCa6c18c_1744272838_quick/TrustedRelayerIsm.zip|TrustedRelayerIsm.zip>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
An error occured while uploading single smart contractSequelizeDatabaseError: invalid input syntax for type integer: "$ID"
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x3Ba40e5275ff828e3bA857e74f593e1E5d51eb21_1744272610_invalid/HypeDetector.sol|HypeDetector.sol>' - uploaded by: <mailto:admin@naoris.com|admin@naoris.com>.
```
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x4e107a0000DB66f0E9Fd2039288Bf811dD1f9c74_1744108730_quick/VLR.zip|VLR.zip>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x02c0733d2F377a43A659102ece56c4Cbc8bCad5F_1744108305_quick/check_ifw.sol|check_ifw.sol>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
No SOL file was found on '2' explorer for '0xd79bb960dc8a206806c3a428b31bca49934d18d7' smart contract address in '2' chain - Uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0xDb82c0d91E057E05600C8F8dc836bEb41da6df14_1744106854_quick/SLN.zip|SLN.zip>' - uploaded by: <mailto:psingh@datopic.com|psingh@datopic.com>.
```
```
An error occured while uploading single smart contractSequelizeDatabaseError: invalid input syntax for type integer: "$ID"
```
```
'<https://naoris-tokenizer.s3.amazonaws.com/SmartContractAnalyzer_Reports/0x3Ba40e5275ff828e3bA857e74f593e1E5d51eb21_1744106516_invalid/HypeDetector.sol|HypeDetector.sol>' - uploaded by: <mailto:admin@naoris.com|admin@naoris.com>.
```
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.
Reminder: Follow up <!here> on sca-daily pending report status.


--- Messages from #sca-pagerduty-report-notification ---
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```
```
QA ENV 
Reports awaiting publication: none
```


--- Messages from #naoris-sca-testing-notification ---
*MongoDB Health Stats:*
 * Server Status: * OK: 1.0, Uptime: 1794112.0 sec, Connections: 20
*Database Stats:* Collections: 8, Objects: 9881
*Collection Details:*
- `bds_atif.ipset`: 3461 documents
- `cybercrime.ipset`: 1353 documents
- `firehol_webserver.netset`: 3021 documents
- `urlvir.ipset`: 171 documents
- `et_compromised.ipset`: 312 documents
- `blocklist_de_bruteforce.ipset`: 202 documents
- `last_sync`: 7 documents
- `et_block.netset`: 1354 documents

```
New Form Submission Alert!

      Name: [AVANISH KUMAR]

      Email: [avanishkumarr8@gmail.com]

      Phone Number: [07834873044]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [AVANISH KUMAR]

      Email: [avanishkumarr8@gmail.com]

      Phone Number: [07834873044]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [AVANISH KUMAR]

      Email: [avanishkumarr8@gmail.com]

      Phone Number: [07834873044]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [Avanish]

      Email: [avkumar@dat]

      Phone Number: [7834873044]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [Swati chauhan]

      Email: [SWATICHAUHAN5458@GMAIL.COM]

      Phone Number: [9310499615]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [Avanish Kumar]

      Email: [avanishkumarr8@gmail.com]

      Phone Number: [7834873044]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [AVANISH KUMAR]

      Email: [avanishkumarr8@gmail.com]

      Phone Number: [7834873044]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [Saurabh Jain]

      Email: [jainsaurabh78@gmail.com]

      Phone Number: [09899382379]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [Avanish]

      Email: [avkumar@datopic.com]

      Phone Number: [7834873044]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [test]

      Email: [vichauhan@datopic.com]

      Phone Number: [979779797979]

      Please follow up promptly!
    
```
```
New Form Submission Alert!

      Name: [test]

      Email: [vichauhan@datopic.com]

      Phone Number: [9876543210]

      Please follow up promptly!
    
```
Domain Checks:
Component: <http://localhost:8080> - Status: Fail
Component: <http://localhost:50051> - Status: Fail

```
🔔 *New Candidate Alert!* A new candidate has applied on Python Django Developer. You can view their resume here: <https://s3.amazonaws.com/datopic.com/uploadedresumes/6f3fc622-1876-4855-8bbb-db85f5c7fef0_Bargraph_icon.svg|View Resume>.
```
```
🔔 *New Candidate Alert!* A new candidate has applied. You can view their resume here: <https://s3.amazonaws.com/datopic.com/uploadedresumes/18a1bc87-808e-4863-af31-22a822d94e2a_Bargraph_icon.svg|View Resume>.
```
```
New resume uploaded - <https://s3.amazonaws.com/datopic.com/uploadedresumes/7e2e02c2-35d4-48ea-94b5-573babddc1a0_Bargraph_icon.svg>
```
```
New resume uploaded - <https://s3.amazonaws.com/datopic.com/uploadedresumes/98097144-7ee3-4370-9bb0-c2da4a3dfe78_Bargraph_icon.svg>
```
```
New resume uploaded - <https://s3.amazonaws.com/datopic.com/uploadedresumes/524a5b68-e9ca-43d6-8793-098dd9e8978c_Screenshot%202024-10-04%20at%203.41.10%C3%A2%C2%80%C2%AFPM.png>
```
```
New resume uploaded - <https://s3.amazonaws.com/datopic.com/uploadedresumes/7e2a8de9-604e-4748-bdde-d83f8c211ede_Aryan_Rusiya_Resume_.pdf>
```
<@U05LSGYDT70> has joined the channel
```
New resume uploaded - <https://s3.amazonaws.com/datopic.com/uploadedresumes/680d1b55-f06d-4b87-a7f2-f51c61336aff_Bargraph_icon.svg>
```
```
New resume uploaded - <https://s3.amazonaws.com/datopic.com/uploadedresumes/82d951cc-3ee1-46ea-95d3-62d57e8b9c58>
```
```
Resume uploaded success.
```
```
Resume uploaded success.
```
Finexus-api is Up
Finexus-api is down
Clone of Finexus-api is down
finexusAPI is down
Clone of Finexus-api is down
finexusAPI is down
Finexus-api is down
Finexus-api is down
Clone of Finexus-api is down
finexusAPI is down
Clone of Finexus-api is down
finexusAPI is down
Finexus-api is down
Finexus-api is down
Finexus-api is down
Clone of Finexus-api is down
<@UMZDDSZ38> has joined the channel
Alert was generated on Opnesearch
Alert was generated on Opnesearch
Failed Checks:
Domain/API: <https://apiagent.naorisprotocol.com/poolapi/get_spare_wallet> - Status: Returned status code 200
Domain/API: <https://devapiagent.naorisprotocol.com/poolapi/get_spare_wallet> - Status: Returned status code 200
Domain/API: <http://3.12.150.45:8000/api/v1/getSpareWalletList> - Status: Returned status code 200

Alert was generated on Opnesearch
Alert was generated on Opnesearch
Alert was generated on Opnesearch
<@U059KQY2UAK> has joined the channel
```
DEVELOPMENT ENV 
Reports awaiting publication: none
```
```
The user '<mailto:naveen.sharma@datopic.com|naveen.sharma@datopic.com>' attempted to upload a file 'consta.sol' that contain external dependencies.
```


--- Messages from #dtp-docosorous-activity-monitoring ---









<!here> Movie Tickets hijacked the interest from here



ok sure will update soon
<@UJHAMN08N> pls create page on docusaurus for Setting UP PostgreSQL on AWS RDS and PYTHON debugger


Docusaurus Docs URL:   <http://54.90.99.24:3006/>


































--- Messages from #dtp-thoughtworks ---
<!here>  Hope you're doing well.
While exploring the Ghibli trend, I was amazed to see the amazing transition in my photograph!!! Curiuos to know more, I discovered :-

                             *Magic behind Ghibli trend- LoRA Fine-tuning + Stacking on Stable Diffusion 3.0*

First of All, *what is "Diffusion" in the "Stable Diffusion"?* At their core, *Diffusion Models* are a type of *generative AI* — models that can _create_ new data (like images) instead of just analyzing it.
Here's the simple idea:
• *Training phase:*
•  Take a real image and slowly *add noise* to it (like static on a TV) until it's just pure noise.
• *Learning phase:*
•  Train a model to *reverse* this process — starting from pure noise and gradually removing noise to recreate an image.
*→ The model "learns" how images are structured, and how to build realistic ones from randomness.*

Now, Lets come to stable diffusion 3.0.
*Stable Diffusion 3.0* is the *latest generation* of the popular *text-to-image ML model* developed by *Stability AI*, released around *early 2025*.
It is a *diffusion model*, which means it *generates images* by starting from pure noise and slowly transforming that noise into a meaningful picture based on the *text prompt* you give it — or based on a *photo or other input image* if you want. *Stable Diffusion* (by Stability AI, released August 2022) made diffusion models _practical_ for everyone.
Key features:
• *Text-to-image generation*: Give it a prompt like "a girl in a magical Ghibli forest," and it generates a beautiful scene.
• *Open source*: Anyone could download, modify, and fine-tune it.
• *Small enough to run locally*: Unlike some giant models, Stable Diffusion could run on a decent GPU.
• *Flexible architecture*: Supports fine-tuning with LoRA, DreamBooth, and other techniques to specialize the model in new styles — like Ghibli art.
*Why it caused an explosion:*
 Before Stable Diffusion, text-to-image was locked behind APIs like DALL-E or MidJourney. Stable Diffusion made this tech *open and hackable*, so artists, developers, and researchers could build anything.

*Stable Diffusion 3.0’s Role in Ghibli-Style Photo Transformations*
Stable Diffusion 3.0 made *photo-to-Ghibli image generation* much more powerful and seamless because of *three key abilities*:

1.  Superior Structure Preservation with ControlNet 2.0
Earlier diffusion models often distorted faces or lost body posture when stylizing photos.
*Stable Diffusion 3.0* natively integrates *ControlNet 2.0* modules (*ControlNet* is a *powerful extension* for models like *Stable Diffusion* that lets you control *_how_ the AI generates images* based on _structures_ from an input image.) , allowing perfect extraction of:
• Pose
• Edges
• Depth
• Semantic layout
Meaning: When you upload a real-world photo (selfie, landscape), 3.0 can *keep the structure intact* while stylizing only the surface textures into Ghibli magic.

2. Effortless Style Transfer with LoRA Stacking
*Stable Diffusion 3.0* natively supports *loading and blending multiple LoRAs at once* without needing heavy scripts.
In Ghibli art generation:
• One LoRA preserves face or photo realism.
• Another LoRA applies Studio Ghibli color grading and brushwork.
• A third LoRA might add dreamy background lighting.
The result is a *perfect fusion* of realism and fantasy — *your photo, reborn as a Ghibli painting*.

3. Native High-Resolution Rendering
Ghibli scenes are known for their rich details — every blade of grass, every shimmering cloud matters.
Stable Diffusion 3.0 can generate *ultra-high-resolution images natively* without clumsy upscaling hacks, meaning:
• *No blurriness*.
• *Fine line preservation*.
• *Texture details* that feel hand-painted.
Your Ghibli-styled image feels *museum-grade*, not just like a filter.

*Feature	                                                     Impact on Ghibli Art Generation*
ControlNet 2.0 Integration	                Real-world pose preservation; no weird distortions.
LoRA Merging/Stacking	                Richer, layered stylistic blends (face + background + vibe).
IP-Adapter Readiness	                        Feed a real photo + text prompts together easily.
Cleaner Training Data	                        Reduces unwanted artifacts in dreamy Ghibli images.
Higher-Resolution Output	                Stunning visuals ready for print-quality art.

*Now, zooming in into step 2:- LoRA*
*LoRA* (Low-Rank Adaptation) is a relatively new approach that has gained significant attention in the field of machine learning, especially for image generation. It offers a more efficient and scalable way to fine-tune large pre-trained models.*LoRA (Low-Rank Adaptation)* is a technique for *fine-tuning large AI models quickly, cheaply, and efficiently* — without needing to retrain everything from scratch.
Instead of updating millions (or billions) of parameters, LoRA *injects small "adapter layers"* into the model and *only trains these lightweight layers*.
In the context of *Ghibli morphing*, here’s how LoRA works:
1. *Start with a pre-trained model* (like Stable Diffusion 3.0). 
2. *Train LoRA adapters* specifically on a dataset of Ghibli-style art (character faces, scenery, lighting).
3. *Merge LoRA into the model* during inference (image generation).
4. *Prompt with a photo + text* ("Ghibli-style dreamy portrait") and generate the result.
 The model keeps all its general skills.But now, it can *stylize outputs* in the distinct Ghibli flavor — *on demand*.

Technically, LoRA modifies *attention layers* inside the model:
• It adds *small matrices (A and B)* that capture the difference between the "normal" model and the "Ghibli-stylized" model.
• During generation, instead of recalculating the whole attention map, the model *just applies A and B*.
• This drastically reduces the number of parameters trained — often by *95–99%*!
Result:
• Tiny fine-tuned files (~10–100 MB instead of GBs).
• Training takes hours, not weeks.
• Easy to combine multiple styles (e.g., "Ghibli + watercolor + futuristic Tokyo").
Technically, LoRA modifies *attention layers* inside the model:
• It adds *small matrices (A and B)* that capture the difference between the "normal" model and the "Ghibli-stylized" model.
• During generation, instead of recalculating the whole attention map, the model *just applies A and B*.
• This drastically reduces the number of parameters trained — often by *95–99%*!
Result:
• Tiny fine-tuned files (~10–100 MB instead of GBs).
• Training takes hours, not weeks.
• Easy to combine multiple styles (e.g., "Ghibli + watercolor + futuristic Tokyo").
*Why LoRA Made the Ghibli Trend Possible*
Before LoRA:
• Fine-tuning Stable Diffusion for Ghibli art would cost thousands of dollars and require a giant GPU cluster.
With LoRA:
• Anyone with a decent GPU (even a consumer laptop) can *train or use a Ghibli LoRA*.
• Hugging Face, Civitai, and other platforms now host *Ghibli LoRAs* ready to plug and play.
• Hobbyists, indie creators, and small studios could now *create magic at scale* — not just big corporations. 
          *Benefit*	                          *Impact on Ghibli Art Generation*
• Efficiency	             Train or fine-tune in hours, not weeks.
• Portability	             LoRA files are tiny (5MB–100MB) compared to huge 4GB base models.
• Modularity	             Swap different styles (e.g., Totoro-style, Mononoke-style) without retraining.
• Accessibility	             Enabled artists without coding or big GPUs to create pro-level outputs.
• Community-driven     Open marketplaces (like Civitai) let anyone share LoRA models freely.
In simple terms:
• *LoRA* (Low-Rank Adaptation) → a lightweight, efficient way to fine-tune huge models on specific styles (like Ghibli) without retraining the entire model.
• *LoRA stacking* → you can now *apply multiple LoRA models together* at generation time.
• *Stable Diffusion 3.0* → launched in early 2025, it made LoRA stacking *natively supported* and much *higher quality* for stylization tasks.
Together, *LoRA fine-tuning + stacking on SD3.0* *allowed super easy, super high-quality stylization* — especially for photo-to-Ghibli transformations.
Artificial Intelligence in Enterprise.

OpenAI dropped this master playbook for AI in enterprises but I totally recommend reading it to everyone.

There's a ton of hype around Generative AI and LLMs right now, everyone's talking about ChatGPT, Gemini, and foundation models.

But here’s the thing almost nobody’s discussing openly: the real game changing insights that smart enterprises are quietly using to stay ahead.

It’s not just about throwing an LLM at every problem.

There's a hidden playbook: finetuning models with your own data, building agentic AI workflows, leveraging synthetic data, or using ensembles instead of a single "do it all" model.

I’ve spent a lot of time exploring what really moves the needle, the strategies that are giving enterprises that quiet advantage no one talks about publicly.

These are crucial, yet often overlooked, insights about AI and LLMs every enterprise leader should know to truly unlock competitive advantage.

I totally recommend checking this pdf: <https://cdn.openai.com/business-guides-and-resources/ai-in-the-enterprise.pdf>
*Firebase studio* :rocket: Platform Alert: Firebase Studio is Live! (Launched April 15, 2025)
Google has officially launched Firebase Studio—a blazing-fast, AI-powered cloud IDE for building and deploying full-stack apps right from your browser!

A cloud-based, agentic development environment designed to accelerate how you build, test, deploy and run production-quality AI applications, all in one place

:bulb: *What’s New?*

• AI-assisted coding with Gemini in Firebase
• Build apps using natural language—supports Next.js, React, Flutter, & more
• Built-in terminal, debugger, and Firebase integration
• One-click deploy to Firebase Hosting, Cloud Run, or your own infra
:warning: *Security & Privacy Tips:*
• Don’t hardcode secrets or API keys
• Use Firebase Rules & IAM policies with caution
• Disable public access to Firestore/Storage unless required
• Review AI-generated code for unsafe logic or security gaps
:lock: *Best Practices:*
• Enable 2FA for Google accounts
• Store credentials in Firebase Configs or Secret Manager
• Monitor logs & access in Firebase Console
• Set up alerts for rule violations or unusual behavior
:link: *Explore Firebase Studio* →<https://firebase.studio/>
:fire: Built to ship faster—without compromising on security!
*<!here>*

:rotating_light: *Security Alert: <https://thehackernews.com/2025/04/malicious-python-packages-on-pypi.html|Malicious Python Packages on PyPI>!* :snake:

Over *39,000 downloads* of *malicious PyPI packages* like `bitcoinlibdbfix`, `bitcoinlib-dev`, and `disgrasya` have been discovered. These packages are designed to *steal sensitive data* and *validate stolen credit card information*.
:small_red_triangle_down: *Impact:*
 Developers who unknowingly install these packages may expose themselves and their users to *data breaches*, *financial fraud*, and *supply chain attacks*.

:gear: *Solution:*
• Carefully verify any third-party packages before use
• Use *virtual environments* to isolate projects
• Stay updated with security advisories
• Use tools like `pip-audit` to detect vulnerable packages

:+1:
:warning: Security Alert: CVE-2025-29927 - Next.js Middleware Authorization Bypass 

Researchers have disclosed a critical vulnerability in Next.js middleware that allows attackers to bypass authorization checks using a specially crafted x-middleware-subrequest header. Affected versions:

12.x &lt; 12.3.5

13.x &lt; 13.5.9

14.x &lt; 14.2.25

15.x &lt; 15.2.3

:mag: Who’s affected?

If your app is self-hosted and uses next start with output: standalone.

If your middleware handles authentication/security checks without additional validation.

If your Next.js version is outdated (check with npm list next).

:white_check_mark: What to do?

Upgrade Next.js ASAP (npm install next@latest)

Mitigation (if upgrade isn’t possible): Block requests with the x-middleware-subrequest header at the web server/proxy level.

Review security layers to ensure critical checks aren’t middleware-dependent.

CVE-2025-29927 | Next.js <https://search.app/jnNwL8RjtTMLNF4u5|https://search.app/jnNwL8RjtTMLNF4u5>
A fascinating look into how Anthropic is uncovering the inner workings of large language models
<https://www.technologyreview.com/2025/03/27/1113916/anthropic-can-now-track-the-bizarre-inner-workings-of-a-large-language-model/|https://www.technologyreview.com/2025/03/27/1113916/anthropic-can-now-track-the-bizarre-inner-workings-of-a-large-language-model/>
<!here> 
Guys if not yet, then pls have a look on this and 
Please try to read more about *Majorana-1*
<!here>
 :link: *<https://thehackernews.com/2025/02/postgresql-vulnerability-exploited.html|PostgreSQL Vulnerability>*

A critical security vulnerability, identified as CVE-2024-10979 with a CVSS score of 8.8, has been discovered in PostgreSQL's PL/Perl extension. This flaw allows unprivileged database users to modify sensitive environment variables, such as PATH, potentially leading to arbitrary code execution or information disclosure.

:mag_right: *Root Cause:*
The vulnerability arises from improper control of environment variables within the PL/Perl extension. This mismanagement enables attackers to alter critical process environment variables, facilitating unauthorized actions even without direct access to the database server's operating system.

:gear: *Mitigation Measures:*
To safeguard your PostgreSQL installations:
1. *Update PostgreSQL:* Upgrade to the latest patched versions: 17.1, 16.5, 15.9, 14.14, 13.17, or 12.21, where this vulnerability has been addressed. 
2. *Restrict Extensions:* Limit the `CREATE EXTENSIONS` permission to specific, necessary extensions. Configure the `shared_preload_libraries` parameter to load only required extensions. 
3. *Enforce Least Privilege:* Restrict roles from creating functions by limiting the `CREATE FUNCTION` permission, adhering to the principle of least privilege. 
By implementing these measures promptly, you can mitigate the risks associated with this vulnerability and enhance the security of your PostgreSQL environment.
<!here>
*"Recently, a problem raised by PM Narendra Modi at the Paris AI Summit 2025 caught my attention. I want to share it with you all."*
At the AI Action Summit 2025 in Paris, Prime Minister Narendra Modi highlighted an interesting limitation in AI—when asked to generate an image of a person writing with their left hand, AI often produces an image of right-handed writing. This seemingly simple issue reveals a deeper challenge in AI development: how models interpret and generate content based on their training data.

*Why Does AI Struggle with Left-Handed Writing?*
_A Fascinating Insight into AI Bias and Its Solutions_
*Introduction*
At the AI Action Summit 2025 in Paris, Indian Prime Minister Narendra Modi brought up an interesting example—if you ask an AI model to generate an image of someone writing with their left hand, it will most likely produce an image of right-handed writing. This simple example highlights a much deeper issue: bias in AI models. But why does this happen, and how can we fix it?

*The Root of the Problem: Training Data Bias*
AI models learn from vast amounts of data, and since over 90% of the world’s population is right-handed, most images in the training datasets feature right-handed writing. As a result, the AI assumes writing is typically done with the right hand. This isn’t a deliberate error but a byproduct of pattern recognition.
*Lack of Contextual Understanding*
Unlike humans, AI doesn’t “understand” left or right in a spatial sense. It generates images based on probability—choosing what it has seen most often. Even when explicitly asked to generate a left-handed image, it may still default to right-handed writing due to its ingrained patterns.
*Potential Solutions*
1. *Diversifying Training Data* – AI models should be trained with more diverse datasets, ensuring that underrepresented scenarios (such as left-handed writing) are sufficiently included.
2. *Enhancing Prompt Engineering* – More detailed prompts, such as "a close-up of a left hand holding a pen while writing," can guide the AI more effectively.
3. *Human Feedback Loops* – AI systems can improve through reinforcement learning, where human users correct biases in generated content over time.
4. *AI Self-Reflection Mechanisms* – Future AI models could analyze their own biases and actively adjust their outputs based on contextual cues.
*Opportunity:*
This example of left-hand writing may seem trivial, but it reflects a larger challenge in AI development—eliminating biases that unintentionally shape AI behavior. By addressing these gaps, we can create more accurate and inclusive AI systems.
Feel Free to share your thoughts on its reason and potential solutions !!

Attaching an Example Scenario below.
<!here> Hope you all are doing well!!

"As I recently heard the term '*Digital Twins*' mentioned by <@UF8TMD5ST> sir, it piqued my curiosity, and I decided to dive deeper into this fascinating concept. Today, I want to share some insights about what digital twins are, why industries are embracing them, and how they integrate with technologies like AI, IoT, and blockchain to reshape the future of innovation."

*Digital Twins: The Virtual Mirrors Shaping Our Future*

*Imagine a technology that allows you to predict a machine's failure before it happens, optimize factory workflows without disrupting operations, or simulate a city’s traffic patterns in real-time to prevent congestion. This isn’t science fiction—it’s the power of digital twins.*

In simple terms, a digital twin is a virtual replica of a physical object, process, or system that receives real-time data to simulate, analyze, and optimize its real-world counterpart. Technically, it’s a combination of IoT sensors, real-time data streams, and advanced analytics working together to bridge the physical and digital worlds.
Digital twins are not just futuristic concepts—they’re already transforming industries. Let’s explore why they matter and how emerging technologies like blockchain, AI, and IoT amplify their potential.

*Why Industries Are Adopting Digital Twins*
Industries are rapidly adopting digital twins because they unlock *efficiency, predictability, and innovation*. By creating a digital replica of a machine, process, or even an entire ecosystem, organizations can:
• *Enhance Decision-Making:* Simulate real-world conditions to test scenarios without disrupting operations.
• *Predict Failures:* Real-time monitoring and predictive analytics identify potential breakdowns before they happen.
• *Optimize Performance:* Streamline workflows, reduce downtime, and improve resource allocation.
• *Reduce Costs:* Identify inefficiencies and minimize waste across the lifecycle of a product or system.
For instance, in *manufacturing*, digital twins are used to optimize production lines, while in *healthcare*, they simulate personalized treatments for patients.

*The Integration of Emerging Technologies*
Digital twins thrive when integrated with advanced technologies like *IoT, AI/ML, cloud computing*, and *blockchain*. Here’s how these technologies enhance their functionality:
*1. IoT (Internet of Things)*
IoT sensors act as the eyes and ears of digital twins, collecting real-time data such as temperature, pressure, and performance metrics from physical assets. This continuous data stream keeps the digital twin updated and relevant.
*Example:* In smart cities, IoT sensors monitor traffic, feeding data into a digital twin that simulates and optimizes urban mobility.
*2. AI and Machine Learning*
AI and ML analyze the massive datasets generated by digital twins to predict outcomes, detect anomalies, and suggest optimizations. These algorithms also enable simulations of "what-if" scenarios to prepare for future challenges.
*Example:* AI-powered digital twins in healthcare can predict a patient’s recovery trajectory based on their medical history and current vitals.
*3. Cloud and Edge Computing*
Cloud platforms provide the scalability needed to store and process vast amounts of data, while edge computing ensures real-time responsiveness by processing data locally before updating the digital twin.
*Example:* In renewable energy, edge devices monitor solar farms, and the digital twin optimizes energy output based on weather conditions.
*4. Blockchain for Security and Trust*
Blockchain ensures the integrity and security of digital twin data. It provides a tamper-proof ledger for recording all changes and interactions with the twin, building trust in multi-stakeholder environments.
• *Transparency:* Tracks the lifecycle and ownership of a digital twin.
• *Collaboration:* Enables secure, decentralized access for all stakeholders.
• *Automation:* Smart contracts execute actions (e.g., triggering repairs) when specific conditions are met.
*Example:* In supply chains, blockchain-backed digital twins track goods from production to delivery, ensuring authenticity and transparency.

*Real-World Applications*

*Manufacturing:* Digital twins optimize factory operations, predict equipment failures, and improve product designs.
_Example:_ Rolls-Royce uses digital twins for real-time monitoring and maintenance of jet engines.
*Healthcare:* Patient-specific digital twins simulate treatments and predict health outcomes.
_Example:_ A digital twin of a heart allows doctors to test various surgical procedures virtually.
*Smart Cities:* Digital twins help urban planners optimize energy grids, traffic systems, and public services.
_Example:_ Singapore uses a city-scale digital twin to manage infrastructure and improve urban planning.
*Energy:* Digital twins monitor and optimize renewable energy systems.
_Example:_ Wind turbines have digital twins that track performance and schedule predictive maintenance.

*The Road Ahead*
As digital twins continue to evolve, their integration with technologies like AI, blockchain, and IoT will unlock even greater possibilities. From smarter factories and efficient cities to personalized healthcare and sustainable energy systems, the potential applications are vast.
The question isn’t whether digital twins will shape the future—it’s how far their impact will reach.
How do you see digital twins transforming your industry? Let’s discuss!
<!here> :rotating_light: *Must-Read*: How Jira Cloud Transformed Performance with Protobuf! :rocket:

Atlassian has made an incredible leap in optimizing Jira Cloud by switching from *JSON* to *Protobuf*.
The impact?
:bulb: *50% reduction* in cache infrastructure costs
:zap: *75% reduction* in CPU utilization

This shift has significantly improved performance, making Jira Cloud faster and more scalable. If you're interested in the technical details and how Protobuf contributed to these optimizations,
check out the full article here:
:link: <https://www.atlassian.com/blog/atlassian-engineering/using-protobuf-to-make-jira-cloud-faster|Using Protobuf to Make Jira Cloud Faster>
⠀
<!here> "Hey everyone! Hope you all are doing well!!
*PQShield Joins Japan's NEDO Program for Post-Quantum Cryptography!* :star2:
Here's something remarkable in the world of cybersecurity:
:shield: *PQShield Partners with Japan's Cyber Research Consortium (CRC)*
PQShield has joined forces with CRC, funded by NEDO, to fortify Japan’s cybersecurity against quantum-enabled threats. This groundbreaking initiative will run from *2024 to 2026* and involves collaboration with leading organizations like:
• *AIST*
• *Mitsubishi Electronics*
• *The University of Tokyo*
:lock: *Project Highlights*
• Development of *post-quantum cryptographic (PQC)* solutions, including:
    ◦ Ring signatures
    ◦ Threshold signatures
    ◦ Threshold encryption
• Contributions to *global PQC standardization efforts*, with protocols shared with the *Internet Engineering Task Force (IETF)* and cryptographic primitives submitted to *NIST*.
:earth_africa: *Global Impact*
This project aligns with the finalized *NIST PQC standards* (published in August 2024), providing a roadmap to safeguard data against future quantum threats.
:handshake: *Collaboration at its Best*
Dr. Ali El Kaafarani, CEO of PQShield, emphasized:
&gt; _“Securing critical infrastructure from quantum threats requires strong partnerships between governments, universities, and the private sector.”_
PQShield's growing presence in Japan includes partnerships with *Mirise Technologies*, *Sumitomo Electric*, and *NTT Data Group Corporation*.
:book: *Want to Learn More?*
Check out the full report <https://quantumcomputingreport.com/pqshield-joins-nedo-program-to-implement-post-quantum-cryptography-across-japan/|here>.
Let’s celebrate this major step forward in cybersecurity! :rocket:
<!here> Hope you all are doing well!
 I came across a noteworthy read that I wanted to share with you all. It's about a really interesting development in the AI world that I think you'll find pretty fascinating.

*DeepSeek AI Assistant: A Game-Changer in the AI Landscape*
 _Introduction_
The world of artificial intelligence (AI) is constantly evolving, with new breakthroughs and innovations emerging at a rapid pace. One recent development that has captured the attention of the tech world is DeepSeek AI Assistant, a powerful chatbot that has quickly become one of the most popular and talked-about AI tools available today.

*What is DeepSeek AI Assistant?*
DeepSeek AI Assistant is a language model that can engage in conversations, generate creative text, translate languages, write different kinds of content, and answer your questions in an informative way. It is based on the same technology as OpenAI's ChatGPT, but it has been shown to outperform ChatGPT in a number of ways.
*Key Features of DeepSeek AI Assistant*
• *Open-source:* DeepSeek has made its models open source, meaning developers can freely access and modify them.
• *Cost-effective:* DeepSeek claims to have developed its models at a fraction of the cost of its rivals, challenging the notion that massive investment is necessary for cutting-edge AI.
• *High performance:* DeepSeek has shown advanced "reasoning" skills and is considered on par with, or even exceeding, the capabilities of models from OpenAI and other leading companies.
• *Accessibility:* DeepSeek offers unlimited free usage, making powerful AI accessible to a wider audience.
*Why DeepSeek is Making Waves*
• *Topped the App Store:* DeepSeek AI Assistant quickly became the No. 1 free app on Apple's App Store, surpassing ChatGPT.
• *Market disruptor:* Its sudden popularity has sent ripples through the stock market, impacting companies like Nvidia and sparking discussions about the US-China AI race.
• *Challenging US dominance:* DeepSeek's success challenges the perception of US dominance in the AI field and highlights China's growing capabilities.
*The Future of DeepSeek*
DeepSeek is a major player in the AI landscape, and its impact is likely to be felt for years to come. It is a testament to China's growing AI prowess and a sign that the competition in this field is heating up. We can expect to see DeepSeek continue to innovate and evolve, pushing the boundaries of what is possible with AI.
*Conclusion*
DeepSeek AI Assistant is a game-changer that has shaken up the AI world. It is a powerful tool that has the potential to revolutionize the way we interact with technology. I encourage you to try DeepSeek AI Assistant for yourself and see what it can do.
*Additional Resources*
• <https://chat.deepseek.com/|DeepSeek AI Assistant>
• DeepSeek AI Assistant on GitHub]([<https://github.com/deepseek-ai/DeepSeek-R1]>)
• DeepSeek AI Assistant <https://medium.com/@harsh.vardhan7695/deepseek-r1-the-open-source-ai-revolutionizing-technology-1b0914a162da|Medium Blog> 
Thank you for reading!
*Understanding Sprint Burndown Charts* :chart_with_downwards_trend:
A Sprint Burndown Chart, as the name suggests, shows you the total work completed within a sprint, and the total work remaining.
Burndown Charts are a good way to predict regarding the likelihood of teams completing the work on time.

:white_check_mark: _*Major Insights*_
1. If the team is consistently finishing their work early, it means that they aren't committing to enough work during planning.
2. If the team is consistently missing the forecast, it means they have committed to too much work.
3. It the chart shows a sharp drop during the sprint, this means that the sprint has not been estimated accurately, or broken down properly
:white_check_mark: _*Issue/Work Estimation - A Pre-requisite to creating a Burndown Chart*_
  Estimate your issues - either using story points / hours  (Example: In Smalter we are using hours as the estimation statistic).
  Changing an estimate - If you change the estimate once the sprint has started, it will show up as a spike in the work scope on the chart
  One cannot stress enough on the importance of correctly estimating the work issues.

:white_check_mark: _*Reading the Burndown Chart* (Please refer to the 1st image attached with 1, 2 and 3 marked)_
• Y-Axis - Refers to the estimation statistic you have selected 
• Red Line - The red line refers to the total amount of work left in the Sprint, according to team's estimates. 
• Ideal Guideline - Grey Line refers to where the team need to be, assuming linear progress
          If your red line is below the grey line, you're on track to completing the work on time.
---------------------------------------------------------------------------------------------------------------------------------------
 Note: I have posted the Sprint Burndown Chart for Smalter Project as of today (Refer 2nd attached image)

 Q1: What is the estimation statistic used to create the Burndown Chart?
 Q2: Looking at the chart, do you think that the team will complete the work on time?
 Q3: Can you estimate the reasons for the flat lines, parallel to the x-axis, visible on the chart?
 Q4: Looking at the chart, do you think there has been a scope change in the sprint after the sprint started?

Please feel free to engage in comments (also post your answers...:blush:)

Have a great day. Cheers. :+1:
Dear Ujjawal - good work. Possible to find out how this could help us further enhance capability of our own product - Intellichat?
<!here> Guys pls have a look on Latest Information regarding a Trojan

Malicious NPM Package Disguised as an Ethereum Tool Deploys Quasar RAT

Seems interesting??
Okay! lets deep dive into the this : -


Cybersecurity *researchers* have discovered a *malicious* package on the *npm package registry*.
That is actually designed as a library for detecting vulnerabilities in Ethereum smart contracts but,
In reality, drops an open-source remote access *trojan* called *Quasar RAT* onto developer systems.

The heavily obfuscated package, named *ethereumvulncontracthandler*, was published to npm on *December 18, 2024*,
by a user named "*solidit-dev-416*"

Upon installation, it retrieves a *malicious script from a remote server*, executing it silently to deploy the *RAT on Windows systems*

The malicious code embedded into ethereumvulncontracthandler is obscured with *multiple layers of obfuscation*, leveraging techniques
like Base64- and XOR-encoding, as well as minification to resist analysis and detection efforts.
The script is designed to run PowerShell commands to initiate the execution of Quasar RAT.

The remote access trojan, for its part, establishes persistence through Windows Registry modifications and contacts a command-and-control (C2)
server ("captchacdn[.]com:7000") to receive further instructions that allow it to gather and exfiltrate information.

This package contained malicious code and was removed from the registry by the npm security team. A placeholder was published to ensure users are not affected in the future.

And Yes of-course please make sure to check the information of unknown and new NPM packages to
ensure security of your systems and protect data of our organization from such trojans.

To check complete article please <https://thehackernews.com/2025/01/malicious-obfuscated-npm-package.html?m=1|ClickHere>
*Fake Zoom Meeting Links Lead to Million-Dollar Cryptocurrency Heist*
Yes you read it right..
<!here> Today I went through an article regarding how a sophisticated phishing campaign masquerading as Zoom meeting invitations has resulted in the theft of millions in cryptocurrency, as revealed by a recent analysis from blockchain security firm SlowMist. By exploiting users’ trust in commonly used communication platforms, attackers have managed to deploy malware that compromises systems and siphons sensitive data, including cryptocurrency wallets.
The phishing links, designed to mimic legitimate Zoom meeting invitations, directed users to a fraudulent domain, *“app[.]us4zoom[.]us”*, which closely resembled the genuine Zoom interface. Instead of launching the Zoom client, clicking on the “Launch Meeting” button prompted the download of a malicious installation package named *“ZoomApp_v.3.14.dmg.”*

According to SlowMist, the site’s backend logs revealed evidence of *Russian-language scripts* monitoring downloads via the Telegram API. “_Since November 14, they have been targeting victims and using the Telegram API to monitor whether anyone clicked the download button on the phishing page._

Once downloaded and executed, the fake Zoom application prompted users to enter their system passwords, a step that facilitated deeper infiltration. The malicious software employed a script named *“ZoomApp.file”* to execute additional code, ultimately activating a hidden executable file called *“.ZoomApp.”* This program systematically collected sensitive data, including:
• *System information*
• *Browser data*
• *Cryptocurrency wallet keys*
• *Telegram and Notes data*
• *Cookies and KeyChain passwords*
The gathered information was then compressed and sent to a hacker-controlled server located at *141.98.9.20*, flagged as malicious by threat intelligence platforms.
Using the *MistTrack* on-chain tracking tool, *SlowMist* identified the hacker’s address, *0x9fd15727f43ebffd0af6fecf6e01a810348ee6ac*, which has amassed over $1 million in stolen funds, including *ETH*, *USD0++*, and *MORPHO*. The stolen assets were swapped for *296 ETH*, a portion of which was subsequently laundered through platforms like Binance, <http://Gate.io|Gate.io>, and Swapspace.

Interestingly, SlowMist uncovered a supporting address, *0xb01caea8c6c47bbf4f4b4c5080ca642043359c2e*, suspected of acting as a transaction fee provider, transferring small amounts of ETH to nearly 8,800 addresses. These findings connect the phishing operation to broader malicious networks, including tags like *“Pink Drainer”* and *“Angel Drainer.”*

SlowMist emphasizes the importance of user vigilance, advising individuals to:
1. *Verify meeting links* before clicking.
2. Avoid executing unknown files or commands.
3. Regularly update and use reputable antivirus software.
4. Secure cryptocurrency assets with strong, multi-layered defenses.
As the report concludes, “_These types of attacks often combine social engineering and Trojan techniques, making users vulnerable to exploitation_.”
hey team, <!here>
*Exciting news: Quantum teleportation over existing internet infrastructure has been achieved! Sharing this article for insights into its implications for secure communication and quantum-safe technologies.*
*Quantum Teleportation Achieved Over Existing Internet Infrastructure*
In a groundbreaking milestone for quantum communication, researchers from Northwestern University have successfully demonstrated quantum teleportation over existing fiber optic cables carrying active internet traffic. This achievement represents a significant step toward the practical realisation of a quantum internet and has profound implications for secure communication and advanced computing.
*Key Details of the Breakthrough*
1. *Integration with Current Infrastructure*:
    ◦ The experiment utilized standard fiber optic cables already in use for internet traffic. This indicates that future quantum networks may not require entirely new infrastructure, which could drastically reduce deployment costs and accelerate adoption.
2. *Quantum Entanglement in Action*:
    ◦ The process of quantum teleportation relies on entangled particles. In this experiment, researchers successfully teleported quantum information between two distant points without physically transmitting the particles themselves. This underscores the potential of quantum mechanics to revolutionise communication technologies.
3. *Real-World Implications*:
    ◦ By demonstrating that quantum communication can coexist with classical internet traffic, this research paves the way for a hybrid network architecture. Such a system could enable ultra-secure communication methods that are resistant to eavesdropping and data breaches.
*Potential Applications in Cybersecurity and Quantum-Safe Technologies*
• *Reinforced Secure Communications*: As a company focused on cybersecurity, this advancement aligns with the pursuit of quantum-safe encryption algorithms. Quantum teleportation could bolster the development of encryption methods that are not only resilient to classical attacks but also impervious to quantum computing threats.
• *Enhanced Key Distribution*: Quantum key distribution (QKD) integrated with teleportation methods could redefine secure communication standards, ensuring robust protection for sensitive data.
• *Quantum-Resistant Algorithms*: The ability to utilise entangled states in real-time traffic scenarios complements efforts in creating and deploying quantum-resistant cryptographic algorithms.
*Why This Matters for Our Organisation*
This breakthrough underscores the growing intersection between quantum communication technologies and cybersecurity. As we develop quantum-safe applications and explore future-ready security measures, understanding and leveraging such advancements will position our organisation as a leader in the field. Moreover, the demonstration that quantum systems can integrate with existing internet infrastructure highlights the immediate relevance of these technologies to our ongoing projects and strategies.
*Further Reading*
For a detailed exploration of this research and its implications, refer to the original article: <https://news.northwestern.edu/stories/2024/12/first-demonstration-of-quantum-teleportation-over-busy-internet-cables/|Northwestern News>.
*Call to Action*
Let us consider how this milestone can influence our roadmap for cybersecurity and quantum-safe innovation. By staying informed and adapting to these technological shifts, we can reinforce our leadership in securing the quantum-powered future.
.
Hi everyone, Hope you all are doing well!!!

I came across a noteworthy read that I wanted to share: <https://thehackernews.com/2024/12/new-linux-rootkit-pumakit-uses-advanced.html|New Rootkit : PUMAKIT>

The article is about a newly discovered malware for Linux systems called *PUMAKIT*, which is a type of malicious software known as a "rootkit." A rootkit is designed to hide its presence on a computer, take control of certain parts of the system, and avoid being detected by security tools.
Here’s a simplified breakdown of what PUMAKIT does:

*What PUMAKIT is:*
• It’s a very advanced and sneaky type of rootkit that can:
        ▪︎ Gain high-level (admin) access to a computer.
        ▪︎ Hide files, directories, and itself so users and system tools can’t see it.
• Communicate secretly with its creators (command-and-control servers).
*How it works:*
• *Multi-layered design:* PUMAKIT has several parts working together, including:
        ▪︎ A dropper: This is the initial piece that gets the malware onto the computer. It’s disguised as a normal system program called "cron."
        ▪︎ Memory-resident executables: These parts ("tgt" and "wpn") stay in the computer’s memory without leaving visible traces on the disk.
        ▪︎ A kernel module: This is the main component called "*puma.ko*" that interacts with the system’s core (the kernel) to hide itself and take control.
• A user-level tool: This tool, called "*Kitsune*," helps the malware communicate and operate from the user’s perspective.
*Tricks PUMAKIT uses:*
    ◦ *Hiding itself:* It uses advanced techniques to hook into the Linux kernel (the core of the operating system) and alter its behavior. For example, it changes the way system calls work so it can avoid detection.
    ◦ *Privilege escalation:* It uses clever methods to gain full admin-level access. For example, it modifies key system functions like "prepare_creds" and "commit_creds."
    ◦ *Conditional activation:* It only fully activates if certain conditions are met, such as secure boot being disabled or specific kernel features being present.
    ◦ *Fileless execution:* Many of its components don’t leave visible files on the disk, making it harder for antivirus programs to spot them.
*Why it’s dangerous:*
    ◦ PUMAKIT is designed to be extremely stealthy, which means it’s hard to detect and remove.
    ◦ It can modify core parts of the Linux operating system and potentially give attackers complete control over the system.
    ◦ Its design shows how malware is becoming more advanced and specifically tailored to target Linux systems.
*Current understanding:*
    ◦ It highlights the increasing sophistication of threats targeting Linux, a platform often used for servers and critical systems.

In short, PUMAKIT is like a highly skilled burglar that not only breaks into your house but also makes itself invisible, disables your security cameras, and gains control over your locks while communicating with its boss—all without leaving obvious signs.

Stay vigilant and keep learning!:sparkles:
*<!here>* "Hey everyone! Hope you all are doing well!!
*Currently Working on Chromium: Insights from How Chromium Powers Apps Like Slack and VS Code*
As I dive deeper into my project of making *Chromium post-quantum secure*, I’ve been uncovering some fascinating insights about how Chromium operates behind the scenes. While working on Chromium’s complex codebase, I began to realize just how much impact its powerful engine has on modern applications, especially apps like *Slack* and *Visual Studio Code (VS Code)*.

*Chromium: More Than Just a Browser*
Chromium is often recognized as the foundation for browsers like Google Chrome and Microsoft Edge. However, its influence goes much further. It’s the backbone for *Electron*, a framework that lets developers create *cross-platform desktop applications* using web technologies like HTML, CSS, and JavaScript. This is where Chromium powers not only browsers but also productivity apps like *Slack* and *VS Code*.
As I explore the Chromium codebase, I’ve come to appreciate just how seamlessly it integrates web technologies into desktop applications, making them fast, responsive, and reliable.

*Chromium’s Role in Slack*
Slack, the collaboration tool that has revolutionized team communication, relies on Chromium through the *Electron framework*. This is how Chromium boosts Slack’s performance:
1. *Web-Like User Interface*
2. Slack’s interface, built with web technologies, feels polished and responsive thanks to *Chromium’s Blink rendering engine*, which handles all the heavy lifting behind the scenes.
3. *Cross-Platform Consistency*
4. With Chromium, Slack ensures the same great experience across different platforms—*Windows, macOS, and Linux*—by using a unified web-based approach for desktop applications.
5. *Real-Time Messaging and Rendering*
6. Slack’s real-time interactions, such as messages, notifications, and file sharing, are made possible by Chromium’s efficient rendering of dynamic content.
*Chromium in Visual Studio Code*
VS Code is another app powered by Chromium, and it’s a favorite tool for developers worldwide. Here’s how Chromium fuels VS Code’s impressive features:
1. *Powerful UI and Extension Support*
2. VS Code’s interface and extension marketplace leverage Chromium’s rendering capabilities, providing a smooth, web-like experience while supporting a huge ecosystem of extensions.
3. *Integrated Developer Tools*
4. Chromium’s developer tools are embedded in VS Code, allowing developers to debug their code directly within the editor, similar to how they would in a browser.
5. *Cross-Platform Development*
6. Just like Slack, VS Code benefits from Chromium’s ability to offer the same features and performance across *Windows, macOS, and Linux*, making it the ultimate cross-platform code editor.
*My Experience with Chromium in Post-Quantum Security*
While working on this project to *make Chromium post-quantum proof*, I’ve realized just how *resource-intensive* the Chromium codebase can be. Fetching the full codebase for my project has been a challenge, primarily due to the *memory and CPU demands* of Chromium. However, seeing how apps like Slack and VS Code make use of Chromium’s engine has inspired me to push forward.
Chromium’s ability to power both web browsers and applications like Slack and VS Code highlights its versatility and the immense potential it has for modern software development. By making these apps *post-quantum safe*, I’m contributing to the future-proofing of these essential tools.

*Conclusion: Chromium’s Role Beyond Browsers*
Working with Chromium has given me new perspectives on its role in shaping the software landscape. It’s not just a web browser engine; it’s the backbone of numerous desktop applications, enabling a seamless user experience across platforms. As I continue my work on post-quantum cryptography, I look forward to seeing how *Chromium’s* flexibility and scalability can evolve to meet the challenges of a post-quantum world.
Good work Prerna! Find time to do a little more research and may be conduct a session for everyone to showcase interesting cases, where it could be used at Datopic
*<!here> Hey everyone! Hope you’re doing well!*
*Upon my exploration in Agentic AI ,I came across a new self-hosted AI tool Khoj .*
*Agentic AI: Redefining Autonomy in Artificial Intelligence*
Agentic AI is revolutionizing how we interact with technology. Unlike traditional AI, it empowers autonomous systems to analyze data, set goals, and take actions with minimal human input. By combining cutting-edge techniques like large language models (LLMs), machine learning, and reinforcement learning, Agentic AI achieves near-human cognition.
:thinking_face:*Why is it game-changing?*
• *Autonomy in Action:* It doesn’t just automate tasks—it enables systems to adapt, learn, and solve complex problems independently.
• *Beyond Creativity:* While generative AI focuses on creating, Agentic AI excels in decision-making and execution, making it an ideal partner for industries requiring strategic thinking.
*Latest Developments:*
Agentic AI is inspired by human intelligence, capable of handling dynamic environments and constantly improving with experience.

:rocket:*Khoj: A Practical Example of Agentic AI in Action*
Khoj, powered by Agentic AI, redefines how we discover and use information. It’s not just a search tool—it’s an intelligent assistant that understands your intent, analyzes context, and delivers precise, actionable insights.
*Key Features of Khoj:*
• *Smart Search:* Goes beyond keywords to provide relevant, context-aware results.
• *Continuous Learning:* Adapts to user behavior, making results more accurate over time.
• *Versatile Applications:* Ideal for professionals, students, and businesses, enhancing efficiency and decision-making.
*How is Khoj Useful?*
• *For Researchers and Professionals:* Quickly access reliable data for projects.
• *For Businesses:* Make data-driven decisions effortlessly.
• *For Students and Educators:* Simplify complex searches and gain deep insights.
Khoj showcases how Agentic AI can simplify complex processes, save time, and improve outcomes, making technology an indispensable partner.

Go to <https://app.khoj.dev> to see Khoj live.

For further learning and documentation refer to : <https://github.com/khoj-ai/khoj>
Recently all of you must have heard and read about 'Electricity Theft' in Sambhal. Many entities had set up elec distribution systems that was being taken away for govt supply chain. Some estimates say that each such entity may have used around 7Cr worth of power in the last year alone.

*Problem Statement*
Is it possible to create an energy utilization and monitoring product that could pin-point the leakage in the distribution pipeline? I understand that water distribution has possibly system that could identify such leakages. I am not sure about this though.

Energy security is one of the biggest global challenges. Leakage will be a challenge for every energy company in nearly every country.

*Is it good enough for us to think about it?*
<!here> Hi team, found some interesting news.
Google has recently released a new Python GenAI library to integrate Google's generative models into Python applications.
*google-genai* is an initial Python client library for interacting with Google’s generative AI APIs. This SDK provides an interface for developers to integrate Google’s generative models into their Python applications. This is an early release (version 0.1.0). API is subject to change. Please do not use this SDK in production. For more detail, please check out this.
<https://googleapis.github.io/python-genai/>
<!here> "Hey everyone! Hope you all are doing well!!
*Ensuring VPN Security: How OpenVPN Detects and Handles Replay Attacks:*
When using OpenVPN, you might encounter a log message like this:
```Authenticate/Decrypt packet error: bad packet ID (may be a replay): [#144311] – see the man page entry for --no-replay and --replay-window for more info or silence this warning with --mute-replay-warnings```
This warning can be perplexing but is an essential part of OpenVPN's security features. Let’s dive into what causes this message, its implications, and how to resolve it effectively.
*What Does This Error Mean?*
OpenVPN uses a feature called *tls-auth* to secure its control channel. Every packet sent during this process is assigned a unique ID. If OpenVPN receives a packet with the same ID as one it has already processed, it assumes that the packet is being *replayed* and drops it.
This mechanism prevents potential *Man-in-the-Middle (MITM) attacks*, where an attacker could try to intercept and replay packets to compromise the connection. The warning indicates that such duplicate packets have been detected and discarded, ensuring the connection remains secure.
*Why Replay Detection Matters*
Replay detection is vital for preventing:
1. *Replay Attacks*: Malicious actors could resend intercepted packets to disrupt or exploit the VPN session. OpenVPN drops such packets, preserving the connection’s integrity.
2. *MITM Attacks*: Even if a MITM attack attempts to resend captured packets, OpenVPN ensures they are detected and rejected.
*Common Causes of Replay Warnings*
1. *Benign Network Behavio*BehaviorBehavior*r*:
       Misconfigured routers or unstable Wi-Fi may resend duplicate packets, causing false alarms.
 *2.    Routing Issues*:
       Some internet systems improperly resend packets already received, triggering warnings
 *3.   Stale ISP Caching*:
       Outdated ISP routing tables can route packets through problematic systems, creating duplicates.
*Resolving Replay Warnings*
1. *Check the Network*:
    ◦ Switch to another network or reboot your router to refresh ISP routes.
2. *Adjust OpenVPN Settings:*
    ◦ Increase the replay window with `--replay-window`.
    ◦ Suppress warnings using `--mute-replay-warnings` (if benign).
*Conclusion*
Replay warnings show OpenVPN's security mechanisms are active, defending against threats like replay attacks. Addressing these warnings ensures a stable and secure VPN connection.
If you look at the above picture, which is the most critical element?
<!here>
See if you find it useful
AGILE DEVOPS
`
.
Indeed, but the purpose of both the tools are different. Both the tools can complement each other, with Zmap handling large-scale discovery and Nmap providing detailed analysis on identified targets.
e.g.
Zmap  has Limited customization and is primarily focused on scanning for specific ports or IP ranges rather Nmap is highly customizable via NSE (Nmap Scripting Engine) which allows users to write custom scripts for specific tasks.
*<!here>*
Recently I was working on finding the good alternative for shodan, and found the tools like Censys and Rigour and these both tools were using *ZMap* as a network scanner.

*Quick Insight:*
:rocket: ZMap is 1300 times faster than NMap.

*Introduction to ZMap:*
• *Purpose*: ZMap is designed for *Internet-wide network scanning tool,* which is crucial for security applications like *exposing vulnerabilities* and tracking defensive mechanisms.
• *Speed*: It can scan the *entire IPv4 address space* in *under 45 minutes* using a single machine, achieving near the theoretical maximum speed of gigabit Ethernet.
*Technical aspects:*
• *Architecture*: ZMap uses a modular, open-source design that supports various types of probes (TCP SYN, ICMP echo, UDP) and can interface with user-provided code for follow-up actions.
• *Efficiency*: Unlike Nmap, it does not utilize existing OS network stack which is not optimized for immense number of connections, ZMap bypasses these inefficiences by generating *ethernet frames directly*, allowing it to send probes at gigabit line speed from commodity hardware.
• *Stateless Operation*: Unike NMap, ZMap does not scan in batches which results time lost due to blocking and lost due to host timeouts, whereas in ZMap it does not maintain per-connection state and *all the components are fully asynchronous.* Statelessness leads to both *higher performance and increased coverage.*
• *Approach*: ZMap uses the *Shotgun Scanning approach* which always sends static (n) probes per host, Unlike Nmap which track individual hosts and retransmit, where most host does not respond.
• *Scanning Technique*: Unlike NMap, this tool avoid flooding through timing, which is the time lost waiting. Whereas *ZMap scans widely dispersed targets* and sends as fast as the network allows.
:thinking_face: *How do ZMap randomly scans addresses without keeping track of the state and without creating an immense amount of data?*
• ZMap efficiently generate random permutation of IP addresses when scanning large networks. 
• By iterating through a *cyclic multiplicative group,* ZMap effectively generates a random sequence of IP addresses, enabling it to quickly scan large address spaces, this method leverages the mathematical properties of cyclic groups, which guarantee that every element in the group will be visited once when iterating through the group.
ZMap is capable of scanning more than *1300 times faster* than the most aggressive Nmap default configuration, with equivalent accuracy.
Surprisingly, ZMap also finds more results than Nmap.
• *Coverage*: It achieves approximately *98% network coverage* with a single probe per host, making it highly efficient for research applications.
*Applications:*
• *Protocol Adoption*: ZMap can track the adoption of protocols like HTTPS over time, providing valuable insights into Internet trends.
• *Vulnerability Scanning*: It can quickly identify vulnerable devices, such as those affected by *UPnP vulnerabilities*, allowing for timely mitigation.
You can also refer to the research paper attached below for better understanding of *ZMap !!*
It is wonderful to note that our posts are getting traction. Well done
<!here> FraudGPT contributed on this group got good attraction from people out there and we got a lead because of this. Great job <@U04H68D12EN>. Others more to share from this group out in near future so stay tuned. <@U04H68D12EN> collect your surprise gift from <@U03FQTNG9DH> 
Hi, <!here> I want to share something interesting about a domain name I discovered. After the merger of Jio and Hotstar, they wanted the domain name <http://jiohotstar.com|jiohotstar.com>, but some tech-savvy person had already purchased it and sold it earlier. This made me curious about what this practice is called, and I found out it’s known as cybersquatting.
*The meaning of cybersquatting:*
Cybersquatting is a form of cybercrime where the perpetrator buys or registers a domain name that is identical or similar to existing domain with the intention of profiting from a recognizable trademark, company name, or personal name. Crucially, the act is illegal because of the bad faith intent of the squatter. Due to its nature, domain squatting can be considered a form of trademark infringement, though there are differences between the two. There are several types of cybersquatting, and attacks may be carried out with different goals in mind.
To more know <https://www.kaspersky.com/resource-center/preemptive-safety/cybersquatting|https://www.kaspersky.com/resource-center/preemptive-safety/cybersquatting>
<!here> Hi Team,

I am sharing a brief overview of *Sprint Planning* to ensure we are all on the same page. The goal is to align our efforts, understand what needs to be delivered, and collaborate effectively throughout the sprint.
Please take a few minutes to review the following details:

*Sprint Planning Overview*
*Sprint Planning* is a key meeting at the beginning of every sprint in Agile methodology. It helps the team define *what work* will be done in the upcoming sprint and *how* that work will be accomplished. This ensures that the team is aligned and focused on delivering value within the sprint.

1. *Goal of Sprint Planning*
• The main goal of sprint planning is to *define the sprint goal* and determine which *user stories* will be completed during the sprint.
• The team collaboratively estimates the effort required for each task and decides which ones are feasible to complete within the sprint duration (usually 1-4 weeks).
2. *Key Inputs for Sprint Planning*
• *Product Backlog*: A list of prioritized features or user stories.
• *Team Capacity*: Availability of developers, QA, and other team members during the sprint.
• *Velocity*: The historical speed at which the team delivers user stories (used to estimate how much work the team can complete in a sprint).
3. *Sprint Planning Agenda*
• *Review Product Backlog*: The Product Owner (PO) presents the highest-priority items from the backlog.
• *Define Sprint Goal*: The team agrees on the primary goal or focus of the sprint, ensuring that it aligns with business priorities.
• *Select User Stories*: The team discusses and selects user stories that will help achieve the sprint goal. Each story should have clear *acceptance criteria*.
• *Break Down Stories into Tasks*: Once the stories are selected, the team breaks them down into smaller tasks that are easier to work on and track.
• *Estimate Work*: The team estimates the effort required for each story using story points or hours. This helps decide if the work is realistic within the sprint.
4. *QA Involvement*
• *Early Involvement*: The QA team is involved from the start of sprint planning to ensure that they understand the acceptance criteria and start planning test cases.
• *Testing Timeline*: QA will start testing as soon as user stories are marked as “Dev Done,” which means development on that story is complete.
5. *Outcome of Sprint Planning*
• A *clear sprint backlog* containing user stories and tasks that the team will complete.
• A shared understanding of the *sprint goal*.
• A commitment from the entire team to collaborate and deliver the planned work by the end of the sprint.
6. *Sprint Planning Best Practices*
• *Stay focused on priority work*: Choose the most important tasks that align with the sprint goal.
• *Collaborate*: Both development and QA teams should collaborate closely to ensure a smooth flow of work and timely testing.
• *Be realistic*: Avoid overcommitting by selecting an achievable amount of work based on the team's capacity and past velocity.
If you have any questions or suggestions about the process, feel free to reach out or bring them up. Looking forward to working together and achieving our sprint goals!

Thanks for reading. Hope It will help everyone to manage the JIRA and sprint.
.
<!here>

*Currently we are working on post quantum cryptographic encryption : Dilithium 3 &amp; 5  (a finalist by NIST)*
*But do you know how this algorithm has been generated or what is its backbone?*

*Let me explain in brief :-* 

The mathematical core of _Dilithium_ is, as with *FrodoKEM*, based on the hardness of a variant of the Learning with Errors (*LWE*) problem and the Short Integer Solution (SIS) problem.

To understand above concept you need to understand how these algorithms gets generated:
• Its mathematical underpinnings:  a cryptographic algorithm can be built as a *Matryoshka doll* or Chinese box. Let us use the Chinese box analogy here. The first box, in this case, is the mathematical base, whose hardness should be strong so that security is maintained. In the post-quantum world, this is usually the hardness of some lattice or isogeny problems.
• Its algorithmic construction: these are all the subsequent boxes that take the mathematical base and construct an algorithm out of it. In the case of a signature, first one constructs an identification scheme, which we will define in the next sections, and then transform it to a signature scheme using the *Fiat-Shamir transformation*.

Hey <!here>,
A new undetected Linux malware called *Lightning Framework* has been discovered. This versatile threat has the ability to install rootkits, making it particularly dangerous.
To learn more about Lightning Framework and how it works, check out this informative article:
<https://intezer.com/blog/research/lightning-framework-new-linux-threat/>

<!here> "Hey everyone! Hope you all are doing well!!

Check out this article on the latest blockchain trend.
*Tokenization  of Real-World Assets* :globe_with_meridians: *: Revolutionizing Traditional Markets Through Blockchain*

In the evolving landscape of blockchain technology, one of the latest trends gaining momentum is the tokenization of *Real World Assets (RWA)*. This concept is transforming the way we think about ownership, investment, and financial infrastructure, bridging the gap between the digital and physical worlds.
*What Are Real World Assets (RWA)?*
Real World Assets are tangible, physical assets like *real estate, commodities (e.g., gold), artwork*, and *financial instruments* (like bonds or equity) that are represented as digital tokens on the blockchain. These assets, previously limited by traditional market mechanisms, can now be fractionalized, tokenized, and traded with unprecedented ease and transparency.
With RWAs, you are no longer bound by physical constraints. Blockchain enables a global market where ownership and transactions can happen seamlessly across borders.
*Why Tokenize* :coin: *Real World Assets?*
Tokenization is not just a buzzword—it’s a game-changer. Here’s why RWAs on blockchain are gaining so much traction:
1. *Fractional Ownership*: Imagine owning a slice of a luxury real estate property or a piece of a Picasso painting. Tokenization allows assets to be broken down into smaller fractions, making high-value assets more accessible to a larger pool of investors. For example, instead of buying an entire $1 million apartment, you could own 1% of it through a token representing your share.
2. *Enhanced Liquidity*: Traditionally, assets like real estate or fine art have been illiquid, requiring significant time and cost to sell. However, once tokenized on a blockchain, these assets can be traded 24/7 on decentralized exchanges, allowing for more liquidity and efficient pricing mechanisms.
3. *Reduced Transaction Costs*: Blockchain’s decentralized nature cuts out intermediaries (like brokers or escrow services), reducing transaction fees and enabling peer-to-peer trades in a secure and trustless environment. This can drastically reduce the cost of transferring ownership of high-value assets.
4. *Global Participation*: Blockchain opens the door to global markets. Regardless of geographical location, anyone with internet access can invest in RWAs. This is particularly useful for regions where investment opportunities in certain asset classes may be limited.
5. *Transparency and Security*: Blockchain provides an immutable and transparent ledger of transactions. Ownership history, valuation data, and asset performance are visible to all parties, increasing trust and reducing the risk of fraud. Smart contracts ensure that the terms of any transaction are automatically enforced without the need for manual intervention.
*How RWA Tokenization is Already Transforming Industries*
Several industries are embracing the potential of RWA tokenization:
• *Real Estate*: Tokenized real estate is enabling fractional ownership of high-value properties. Platforms like RealT and Landshare are already leveraging blockchain to allow users to buy tokens representing real estate ownership.
• *Commodities*: Gold-backed tokens such as PAX Gold and Tether Gold allow investors to own fractional shares of physical gold, making it easy to gain exposure to this traditionally stable asset class without dealing with storage or logistics.
• *Fine Art*: Masterworks is an example of a platform allowing users to buy shares of famous art pieces. Tokenization is opening up the art world to more people, democratizing access to high-value collectibles.
• *Financial Instruments*: Bond tokenization is enabling quicker, more transparent bond issuance and trading. Tokenized bonds offer faster settlements, reduced costs, and access to a global market of investors.
*The Future of RWA and Blockchain* :rocket:
The integration of RWAs and blockchain technology is not just a trend—it represents the future of asset management and investment. Blockchain can potentially redefine the financial landscape by democratizing access to previously exclusive markets, reducing barriers to entry, and bringing enhanced efficiency and transparency to asset transactions.
As blockchain developers, we are at the forefront of this revolution. By building more secure, scalable, and user-friendly platforms for RWA tokenization, we have the opportunity to redefine the way people think about investing, ownership, and wealth distribution.
Let’s continue innovating, experimenting, and pushing the boundaries of what’s possible in the blockchain space. The future is tokenized, and we’re just getting started.

*What are your thoughts on the rise of RWA tokenization? How do you see it impacting traditional markets in the coming years?* *Feel Free to connect and share your thoughts on this.*
<!here>
Hii team
Today I read an article on "New Linux Malware detected "*Hadooken Malware" "* that targets Weblogic Applications.
I found it interesting so providing the brief of it.

Aqua Nautilus researchers identified a new Linux malware targeting Weblogic servers. The main payload calls itself Hadooken which we think is referring to the attack “surge fist” in the Street Fighter series. When Hadooken is executed, it drops a Tsunami malware and deploys a cryptominer. In this blog, it  explain the malware, its components, and how it is detected it. Also the Attack flow and it's MITRE ATT&CK mapping is provided.

For details you may visit the link below.
<https://www.aquasec.com/blog/hadooken-malware-targets-weblogic-applications/?web_view=true|https://www.aquasec.com/blog/hadooken-malware-targets-weblogic-applications/?web_view=true>

Thanks.
<!here> Sharing some recent Blockchain news:

India recently launched its *National Blockchain Framework (NBF)*  on *September 4, 2024*, by the Ministry of Electronics and Information Technology (MeitY) , a major initiative aimed at enhancing security, transparency, and digital trust in various citizen-centric applications. The framework, unveiled by the Ministry of Electronics and Information Technology (MeitY), introduces several components, including the *Vishvasya Blockchain Technology Stack*, which offers *Blockchain-as-a-Service (BaaS)*. This stack is hosted on geographically distributed infrastructure, located at National Informatics Centre (NIC) data centers across cities like Bhubaneswar, Pune, and Hyderabad.

The framework is designed to support permissioned blockchain platforms, ensuring secure and scalable solutions. The launch also included *NBFLite*, a lightweight blockchain platform aimed at startups and academia for rapid prototyping and research, as well as *Praamaanik*, a blockchain-based tool for verifying the origin of mobile apps.
The initiative's goal is to position India as a global leader in blockchain technology, driving innovation in governance by making public services more transparent and efficient. The NBF focuses on tackling challenges related to security, interoperability, and scalability in blockchain applications.....

wants to read more??
get more details here: <https://www.moneycontrol.com/technology/what-indias-national-blockchain-framework-means-for-digital-governance-explained-article-12815269.html>
<!here>
Just came across an article about hackers hijacking over 22,000 PyPI packages, which could have serious implications for Python developers. 

You can read more about it here: 
<https://thehackernews.com/2024/09/hackers-hijack-22000-removed-pypi.html|https://thehackernews.com/2024/09/hackers-hijack-22000-removed-pypi.html>
*<!here>* "Hey everyone! Hope you all are doing well!!
*Lessons Learned from a System Misconfiguration: Uninstalling OpenSSL*
In system administration, even simple tasks can have significant consequences. Recently, an attempt to uninstall OpenSSL, a key toolkit for secure communications, led to unexpected problems affecting other critical applications.
*The Issue:* The goal was to remove OpenSSL using the `purge` command, which deletes a package and its configuration files. However, this command also removed essential system libraries and dependencies relied upon by other applications like Firefox, Slack, and the Snap package manager. As a result, these applications stopped functioning, and the system became unstable.
*Resolution:* To resolve the issues, I have to opted for a full reinstallation of Ubuntu with the help of <@U04PNHT9QBH> sir and <@U01S0H9ALM9> sir. This approach restored the system to a stable state, reinstated all necessary components, and fixed the problems caused by the dependency removals.
*Key Takeaways:*
1. *Understand Package Dependencies:* Commands like `purge` can have unintended effects on shared libraries and system components. Always check what dependencies might be affected before executing such commands.
2. *Exercise Caution:* Review the impact of system commands and consider less drastic alternatives when possible.
3. *Regular Backups:* Maintain up-to-date backups to safeguard against significant disruptions. Backups are crucial for recovering from unintended changes or system failures.
4. *Test After Changes:* Thoroughly test critical applications after making major system modifications to ensure they function correctly and address any issues promptly.
*Conclusion:* This experience underscores the importance of understanding package dependencies, using system commands carefully, and following best practices for backups and testing. By adopting these practices, we can avoid similar issues and maintain a stable and functional system.
<!here> "Hey everyone! Hope you all are doing well!!
Recently, I encountered an interesting issue while using OpenVPN, which made me rethink how SSL/TLS certificates are handled in various network configurations. The problem arose when I noticed that I couldn't connect to any websites via my browser after enabling OpenVPN. The root cause turned out to be something I hadn't anticipated: an SSL error due to an improper certificate configuration in the VPN setup. Here’s how it happened and what I learned from it.
*The Problem: SSL Error Blocking My Browser Searches:*
After enabling OpenVPN on my system, I noticed that every time I tried to search for something in my browser, I was met with an SSL error. The connection simply wouldn't go through, and I was left staring at an error page.
Initially, I thought the issue might be with the websites themselves or my internet connection. But after some troubleshooting with the help of <@U04PNHT9QBH> sir, it became clear that the issue was occurring because of the VPN setup I had just enabled. The browser wasn’t able to perform SSL/TLS handshakes properly, and as a result, it was blocking all my search requests.
*Understanding What Went Wrong: The OpenVPN Certificate Issue*
Digging deeper, I realized that when OpenVPN was enabled, every search or request made in my browser was first routed through the VPN setup before reaching the actual website. This rerouting is normal for VPNs, as all traffic is tunneled through the VPN server for security and anonymity.
However, something unexpected was happening during this process. Instead of my browser receiving the SSL/TLS certificate from the target website, it was receiving the SSL/TLS certificate from my OpenVPN setup. That certificate, unfortunately, had exceeded the allowed length, triggering an SSL error in my browser. This was why I couldn’t connect to any websites.
*Why SSL/TLS Certificates Matter in VPN Setups*
SSL/TLS certificates are essential for ensuring that the connection between your browser and a website is secure. When you visit a website, your browser expects to receive a certificate from the server that verifies the identity of the website and establishes an encrypted communication channel.
In my case, the VPN setup was configured in such a way that it used its own SSL/TLS certificate for outgoing connections. This led to a situation where the browser got confused and attempted to use the OpenVPN certificate instead of the website’s certificate. Because the VPN’s certificate didn’t meet the browser’s requirements (due to its length), the connection failed.
This experience highlighted how crucial it is to configure certificates properly, especially when using VPNs. SSL/TLS certificates need to adhere to specific standards in terms of length and cryptographic algorithms. If they don’t, browsers will flag them as invalid, preventing connections from being established.
*Conclusion*
My encounter with SSL errors while using OpenVPN was a valuable learning experience. It taught me the importance of correctly configuring SSL/TLS certificates in complex network setups and how seemingly small misconfigurations can lead to significant issues, such as being unable to browse the web.
If you’re using a VPN or setting up one for secure communication, take the time to verify that your SSL/TLS certificates are correctly configured and comply with current standards. Doing so can save you from frustrating SSL errors and ensure that your browsing experience remains secure and uninterrupted.
<!here> Hey everyone! hope you all are doing well !!

Over the past few days, you've probably heard us mention *DePIN* quite a bit. But what exactly is DePIN, and why is it creating such a buzz? Let’s dive in and explore what *Decentralized Physical Infrastructure* Networks are all about, why they’re so important, and how they’re set to revolutionize the way we manage and operate physical infrastructure.

*Title: The Future of Infrastructure : The Rise of DePIN in a Decentralized World* :globe_with_meridians:

*Introduction:* For decades, our world has relied on centralized models to manage essential services and infrastructure. From energy grids to telecommunications, transportation systems, and beyond, these services are controlled by a few centralized entities. While this approach has provided stability, it's increasingly clear that it comes with significant drawbacks: single points of failure, inefficiencies, high costs, and limited transparency.
In contrast, Decentralized Physical Infrastructure Networks (DePIN) offer a revolutionary alternative. By using blockchain technology, DePIN distributes control and management across multiple nodes, facilitating dynamic scaling, improving data privacy, and enhancing resilience. But before we dive into what DePIN brings to the table, let’s take a closer look at the problems inherent in our current centralized models.

*The Problem with Centralized Services:*
1. *Single Points of Failure:* Centralized systems are highly vulnerable because they rely on a single point of control. If one part of the system fails, the entire network can be compromised, leading to significant downtime and service disruption.
2. *High Costs and Limited Scalability:* Centralized services often struggle to scale efficiently. Expanding infrastructure requires significant investment and is often constrained by the limitations of a single governing body.
3. *Lack of Transparency and Accountability:* Decision-making in centralized systems is often opaque, with little to no input from the communities that depend on these services. This can lead to decisions that prioritize profit over public good.
4. *Data Privacy and Security Risks:* Centralized services are also more vulnerable to data breaches and security threats. With all data stored in one place, a single breach can expose sensitive information on a massive scale.
5. *Service Interruption and Downtime:* Centralized control can result in service interruptions due to failures in the central infrastructure. The lack of distributed resources makes it challenging to maintain continuous operation.
*What DePIN* :rocket:*Brings to the Table:*
DePIN leverages blockchain technology to overcome the limitations of centralized models by decentralizing control, ownership, and management across a distributed network. Here’s how:
1. *Distributed Control and Management:*
    ◦ *Power Across Nodes:* DePIN distributes the control and management of infrastructure across multiple nodes in the network. This decentralization minimizes the risk of service interruption and ensures continuous operation with zero downtime.
2. *Scalable and Dynamic Resource Allocation:*
    ◦ *Efficient Scaling:* DePIN facilitates the scaling of hardware resources across a distributed network. This allows for dynamic expansion and optimization, accommodating growth without the bottlenecks associated with centralized systems.
3. *Enhanced Resilience and Fault Tolerance:*
    ◦ *Robust Architecture:* With services distributed across multiple nodes, DePIN enhances resilience, availability, and fault tolerance. The decentralized architecture ensures that even if one node fails, the network remains operational.
4. *Improved Data Privacy and Security:*
    ◦ *Secure and Private:* By leveraging blockchain’s inherent security features, DePIN provides improved data privacy and protection. Data is distributed and encrypted across the network, reducing the risk of breaches and unauthorized access.
5. *Community Governance and Transparency:*
    ◦ *A Voice for All:* Unlike centralized systems, DePIN allows for transparent decision-making processes, often governed by the community itself. Token holders can vote on network changes, ensuring that the interests of all participants are considered.
*How DePIN Uses Blockchain* :chains: *to Manage Physical Infrastructure:*
Blockchain technology is at the core of DePIN, enabling the decentralized management of physical infrastructure. Here's how it works:
• *Complete Service Management*: All aspects of DePIN service management, including device status and performance, are recorded on the blockchain, ensuring transparency and accuracy.
• *Real-Time Device Tracking and Availability* :hourglass:: Devices are tracked in real-time on an immutable blockchain ledger, providing a secure and transparent view of the network's operational status.
• *Smart Contracts for Automation:* Smart contracts automate operations, maintenance, and transactions within the DePIN network. These self-executing contracts ensure that all parties fulfill their obligations, reducing the need for intermediaries and increasing efficiency.
• *Decentralized Governance:* DePIN networks use decentralized governance models where decisions are made through community voting. This ensures that the network evolves in a way that reflects the collective interests of its participants.
• *Rewarding Mechanism* :moneybag:*:* DePIN incorporates a blockchain based rewarding system where participants earn tokens for contributing to the network. This can include providing infrastructure services, maintaining equipment, or actively participating in network governance. The rewards incentivize engagement, drive network growth, and align the interests of participants with the success of the DePIN infrastructure.
*Conclusion:* The shift from centralized to decentralized infrastructure management is more than just a technological evolution; it’s a fundamental change in how we think about and manage the physical networks that power our world. DePIN offers a more resilient, scalable, and transparent alternative to traditional models, ensuring that the services we rely on are more secure, efficient, and democratically governed. As we move into this new era, DePIN stands poised to redefine the future of infrastructure, bringing the benefits of decentralization to the physical world.

*For further information or to discuss more, feel free to reach out . Let’s work together to explore the potential of DePIN and how we can contribute to building a more decentralized, resilient, and innovative future for infrastructure.*
<!here> *Hey team! I hope everyone’s doing well!*

I came across an noteworthy read that I wanted to share: <https://thehackernews.com/2024/07/github-token-leak-exposes-pythons-core.html|GitHub Token Leak Exposes Python's Core Repositories>.

A recent GitHub token leak exposed critical Python repositories to potential security risks, raising concerns about software supply chain vulnerabilities. The leak was caused by a misconfigured *Docker container* that accidentally contained the *GitHub token*. This token could have allowed attackers to inject malicious code into Python's core components, such as the Python language, Python Package Index (PyPI), or Python Software Foundation (PSF) repositories. The risk was significant, as compromised code could lead to widespread attacks affecting millions of developers and users relying on Python. Upon discovery, the token was promptly revoked, and no malicious activity was detected. However, this incident underscores the importance of securing access tokens and maintaining strict security protocols to prevent similar exposures in the future.

Here are some precautions we can take:
• *Secure Storage:* Keep tokens in secure environments like secret management tools.
• *Access Control:* Apply strict access controls and least privilege principles.
• *Regular Audits:* Conduct frequent security audits to detect vulnerabilities.
• *Token Rotation:* Regularly rotate tokens to minimise risks.
• *Monitoring:* Use monitoring tools to detect unauthorised access.
Stay vigilant and keep learning!:sparkles:


--- Messages from #dtp-tech-training-team ---
:loudspeaker: Announcement *<!here>*: Upcoming Sessions :date:
Hey team!
We are excited to share the lineup of insightful and engaging sessions scheduled for Januray. Please mark your calendars and make sure to attend these informative sessions:
:small_blue_diamond: January 9th Session: To be Conducted by <@U06H9CJGRFE> on Introduction to Kubernetes.
:small_blue_diamond: January 16th Session: To be conducted by <@U06HXEY3NVB> on Cost-cutting Strategies in AWS Cloud.
:small_blue_diamond: January 23rd Session: To be conducted by <@U06CBUXBWMS> on Introduction to DHT.
:small_blue_diamond: January 30th Session: To be conducted by <@U06MYFKMV9U> on Mono Repo.
<!here>
Hi Team,
I observed today that the focus during the training session was lacking. Some were occupied with their laptops, and others seemed disengaged. While I understand that everyone has their own priorities, it’s important to show respect to the speaker by giving them our full attention. Not doing so undermines the purpose of the activity.
If these sessions are not adding value or aligning with our needs, we can reconsider their necessity. The decision is yours to make, but let’s ensure that we approach such opportunities with the respect they deserve.
Thank you
<!here> please join
Ad-hoc Session on Introduction to Storm
Presenter - <@U04HJT17AKB>
PPT Deck - <https://docs.google.com/presentation/d/1R8s9jClUNCgivfwOvqdACvRkKymW_HeO1kC7GgVB3sc/edit?usp=sharing>
Friday, December 20 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/jop-noqo-pyq>
Or dial: ‪(US) <tel:+1470-327-0924|+1 470-327-0924>‬ PIN: ‪585 015 631‬#
More phone numbers: <https://tel.meet/jop-noqo-pyq?pin=1914907202752>
:loudspeaker: Announcement *<!here>*: Upcoming Sessions :date:
Hey team!
We are excited to share the lineup of insightful and engaging sessions scheduled for December. Please mark your calendars and make sure to attend these informative sessions:
:small_blue_diamond: December 5th Session: To be Conducted by <@U06H9CJGRFE> on Introduction to Kubernetes.
:small_blue_diamond: December 12th Session: To be conducted by <@U06HXEY3NVB> on Cost-cutting Strategies in AWS Cloud.
:small_blue_diamond: December 19th Session: To be conducted by <@U06CBUXBWMS> on Introduction to DHT.
:small_blue_diamond: December 26th Session: To be conducted by <@U06MYFKMV9U> on Mono Repo.
<!here> please join
Training Session - Introduction to Metasploit Framework, Presenter <@U06H48HUQFP>
PPT Deck - <https://docs.google.com/presentation/d/1FTfHvR_lTxuA4N9sFmP2ZVeFqGozIAH-UyuB64Q_zWU/edit?usp=sharing>
Friday, November 29 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/txn-nomx-ata>
Or dial: ‪(US) <tel:+1857-529-6541|+1 857-529-6541>‬ PIN: ‪671 516 642‬#
More phone numbers: <https://tel.meet/txn-nomx-ata?pin=2695026001357>
<!here> please join 
*Training Session -* Introduction to DevOPs
*Presenter* <@UTWBT9H8D>
*Presentation Deck* - <https://docs.google.com/presentation/d/1ZaXgfHhscRagKyEqbR2mdnbzQ84EwUGmLr1JzY8eONk/edit?usp=sharing>
*Below is the meeting link:*
Friday, November 22 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/mdz-gvvf-iaz>
Or dial: ‪(US) <tel:+1318-771-7916|+1 318-771-7916>‬ PIN: ‪361 878 317‬#
More phone numbers: <https://tel.meet/mdz-gvvf-iaz?pin=1696096567862>
<!here> Please Join for today's session.
Training Session - Introduction to Modern Front-End Development
Presenter <@U06H48PHUN9>
Presentation Deck - <https://docs.google.com/presentation/d/1JDWH7cyFFCAlNuQmdLVJAkmTUgd7cPPLPkUeg7BMCJ4/edit?usp=sharing>
Friday, November 15 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/tki-tgyw-gqd>
Or dial: ‪(US) <tel:+1530-637-0201|+1 530-637-0201>‬ PIN: ‪674 605 037‬#
More phone numbers: <https://tel.meet/tki-tgyw-gqd?pin=5815025894041>
:loudspeaker: Announcement *<!here>*: Upcoming Sessions :date:
Hey team!
We are excited to share the lineup of insightful and engaging sessions scheduled for November. Please mark your calendars and make sure to attend these informative sessions:
:small_blue_diamond: November 15th Session: To be Conducted by <@U06H48PHUN9> on Introduction to Modern Front-End Development.
:small_blue_diamond: November 21st Session: To be conducted by <@U04MQRR144W> on Introduction to DevOps.
:small_blue_diamond: November 28th Session: To be conducted by <@U06H48HUQFP> on Introduction to Metasploit framework.
Ad-hoc Session - Device Fingerprinting, Presenter - <@U04PNHT9QBH>
Confluence Link - <https://datopic.atlassian.net/l/cp/1BDhHbUN>
Friday, October 4 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/bjn-oxyc-amx>
Or dial: ‪(US) <tel:+1520-800-2160|+1 520-800-2160>‬ PIN: ‪956 672 657‬#
More phone numbers: <https://tel.meet/bjn-oxyc-amx?pin=1053203429661>
<!here> please join
Confluence - <https://datopic.atlassian.net/wiki/spaces/~63dcdcabdb4f715c9721436d/pages/2407825409/Snowflake>
Ad-hoc Session : Snowflake ,Presenter - <@U04MQRR144W>
Monday, September 16 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/nse-obzc-gtn>
Or dial: ‪(US) <tel:+1216-512-0531|+1 216-512-0531>‬ PIN: ‪351 591 820‬#
More phone numbers: <https://tel.meet/nse-obzc-gtn?pin=2373690926087>
<https://datopic.atlassian.net/wiki/spaces/~63bbe73494d18cbf67722b12/pages/2396848132/Configuring+Kdump+and+Kexec>
Steps to configure the Kdump and kexec tools on our system.
Ad-hoc Training Session - Memory Forensics,
Presenter - <@U04HJT1AB2M>
Confluence - <https://datopic.atlassian.net/wiki/spaces/~63bbe73494d18cbf67722b12/pages/2396782603/Memory+Forensics?atlOrigin=eyJpIjoiYWUzOTczMTY0ODllNDdkZDk5ZGZiNWQyZDEzZmUwODUiLCJwIjoiYyJ9|https://datopic.atlassian.net/wiki/spaces/~63bbe73494d18cbf67722b12/pages/2396782603/Me[…]oiYWUzOTczMTY0ODllNDdkZDk5ZGZiNWQyZDEzZmUwODUiLCJwIjoiYyJ9>
Thursday, September 12 · 4:30 – 5:30pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/adv-cjxi-viq>
Or dial: ‪(US) +1 609-795-0187‬ PIN: ‪340 374 650‬#
More phone numbers: <https://tel.meet/adv-cjxi-viq?pin=7073055463658>
<@U06NRRMUR41> as we talked, for ad-hoc sessions, pls ask engineers to inform their supervisor to nominate them for ad-hoc session and it may happen anyfine day
Walk through on Sonar qube
Presenter - <@U059KQY2UAK>
Confluence Link - <https://datopic.atlassian.net/wiki/spaces/~712020b19e331a6885448fb37833f6340d811a/pages/2359296087/Installing+and+Using+SonarQube+on+Linux>
Thursday, September 5 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/fng-dfid-gcb>
Or dial: ‪(US) <tel:+1513-783-1478|+1 513-783-1478>‬ PIN: ‪431 858 718‬#
More phone numbers: <https://tel.meet/fng-dfid-gcb?pin=3375158877781>
<@U06NRRMUR41> Vikrant is not working with us kindly remove his name from the list.
<@U06NRRMUR41>  Ankit, , Saurabh Sharma  and Sumit Kumar both have attended the session just correct it.
You can view your training session attendance here:
<https://docs.google.com/spreadsheets/d/1bNKbIB_gqGTNvIvlVJFnrS8WdpXDBYTV4UmKKs7-Jqs/edit?usp=sharing>
<!here>
Training Session on Containerization and Orchestration
Presenter - <@U022UG2LXEZ>
PPT Deck - <https://docs.google.com/presentation/d/1kD6Q9CtS3UeKnm9G1J1cclQHINxM38wxeFJm6cNK3fI/edit?usp=sharing>
Thursday, August 29 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/ahq-idhw-mmc>
Or dial: ‪(US) <tel:+1219-386-4156|+1 219-386-4156>‬ PIN: ‪199 445 474‬#
More phone numbers: <https://tel.meet/ahq-idhw-mmc?pin=1898031738179>
You can view your training session attendance here:
<https://docs.google.com/spreadsheets/d/1bNKbIB_gqGTNvIvlVJFnrS8WdpXDBYTV4UmKKs7-Jqs/edit?usp=sharing>
*<!here>* Everyone is requested to join today's training session and employees who have joined from WFH are requested to turn on their cameras.
Training Session -  Introduction to Machine Learning
Presenter - <@U06H9HPP736>
PPT Deck - <https://docs.google.com/presentation/d/1uhZrKFGLOp1PeKk-GXgBdHz0FMwVJfyFS0xZGiqkbao/edit?usp=sharing>
Monday, August 12 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/jbx-rkaq-pjd>
Or dial: ‪(US) +1 605-954-4075‬ PIN: ‪984 430 730‬#
More phone numbers: <https://tel.meet/jbx-rkaq-pjd?pin=9526011220682>
~.~
You can view your training session attendance here:
<https://docs.google.com/spreadsheets/d/1bNKbIB_gqGTNvIvlVJFnrS8WdpXDBYTV4UmKKs7-Jqs/edit?usp=sharing>
<!here> Everyone is requested to join today's training session and employees who have joined from WFH are requested to turn on their cameras.
Training Session - Consensus in Blockchain
Presenter - <@U04HVUVP5CG>
Presentation Deck - <https://docs.google.com/presentation/d/1kbjGFznyb03DC7E9BQTHnQqLMq04dWbmIGWeKXGNVZs/edit?usp=sharing>
Thursday, August 1 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/bvs-tobk-yvr>
Or dial: ‪(US) <tel:+1540-692-6647|+1 540-692-6647>‬ PIN: ‪586 571 567‬#
More phone numbers: <https://tel.meet/bvs-tobk-yvr?pin=7532128870802>
:loudspeaker: Announcement *<!here>*: Upcoming Sessions :date:
Hey team!
We are excited to share the lineup of insightful and engaging sessions scheduled for August. Please mark your calendars and make sure to attend these informative sessions:
:small_blue_diamond: August 1st Session: To be Conducted by <@U04HVUVP5CG> on Consensus in Blockchain.
:small_blue_diamond: August 8th Session: To be conducted by <@U04MQRR144W> on DevOps.
:small_blue_diamond: August 12th Session: To be conducted by <@U06H9HPP736> on Introduction to Machine Learning.
:small_blue_diamond: August 22nd Session: To be conducted by <@U06H48PHUN9> on CI/CD Pipelines.
:small_blue_diamond: August 29th Session: To be conducted by <@U06H9CJGRFE> on Mastering Log Analysis with Yara rules
You can view your training session attendance here:
<https://docs.google.com/spreadsheets/d/1bNKbIB_gqGTNvIvlVJFnrS8WdpXDBYTV4UmKKs7-Jqs/edit?usp=sharing>
<@U06NRRMUR41> As we talked, Please share the training session link one day prior.
Employees who have joined from WFH are requested to turn on their cameras.
Training Session - Best Coding Practices to Reduce QA Issues
Presenter - <@U04HJT1B5EV>
Presentation Deck - <https://docs.google.com/presentation/d/1fhxwFu76i29S8dKGqZS80rDI795hNs2hy3sRvAvLzIk/edit?usp=sharing>
Thursday, July 25 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/ohf-qjpm-rzt>
Or dial: ‪(US) <tel:+1904-479-9257|+1 904-479-9257>‬ PIN: ‪761 213 500‬#
More phone numbers: <https://tel.meet/ohf-qjpm-rzt?pin=9946594266352>
You can view your training session attendance here:
<https://docs.google.com/spreadsheets/d/1bNKbIB_gqGTNvIvlVJFnrS8WdpXDBYTV4UmKKs7-Jqs/edit?usp=sharing>
Everyone is requested to join the session .
Training Session - Fully Homomorphic Encryption
Presenter - <@U05GN7RS1D1>
Presentation Deck - <https://docs.google.com/presentation/d/1pxJ4yhhML-aGl-J-Tp9hUhfi4qiBYGcyIieOdlD7F5Q/edit?usp=sharing>
Thursday, July 18 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/qna-vgob-ohs>
Or dial: ‪(US) <tel:+1347-450-2948|+1 347-450-2948>‬ PIN: ‪120 657 353‬#
More phone numbers: <https://tel.meet/qna-vgob-ohs?pin=5329738214191>
You can view your training sessions attendance here:
<https://docs.google.com/spreadsheets/d/1bNKbIB_gqGTNvIvlVJFnrS8WdpXDBYTV4UmKKs7-Jqs/edit?usp=sharing>
<!here>
Training Session - Introduction to Green IT
Presenter - <@U04HJT19EAD>
Presentation Deck - <https://docs.google.com/presentation/d/1oCby-J7Ywmni7UN4NLVJn72RxVuZN100qlk45OTER0g/edit?usp=sharing>
Thursday, July 11 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/pse-jmtf-epx>
Or dial: ‪(US) <tel:+1786-540-5087|+1 786-540-5087>‬ PIN: ‪596 436 476‬#
More phone numbers: <https://tel.meet/pse-jmtf-epx?pin=4655925965634>
You can view your training sessions attendance here:
<https://docs.google.com/spreadsheets/d/1bNKbIB_gqGTNvIvlVJFnrS8WdpXDBYTV4UmKKs7-Jqs/edit?usp=sharing>
<https://docs.google.com/presentation/d/1JfwQ3xtDHCgjdmeL1SxGs75rhEvfjneqVYH3LP9ZqIQ/edit?usp=sharing>
<@U06NRRMUR41> we have Smalter demo today starting from 2:30pm till 5:30pm so few team members would not be available for today's session
<!here>
Training Session on Empowering Work Productivity with Slack API
Presenter - <@U04NARS71G9>
Tuesday, July 9 · 4:00 – 5:00pm
Time zone: Asia/Kolkata
Google Meet joining info
Video call link: <https://meet.google.com/qxp-wesv-ktz>
Or dial: ‪(US) +1 224-970-0567‬ PIN: ‪582 574 081‬#
More phone numbers: <https://tel.meet/qxp-wesv-ktz?pin=6564106359593>
:loudspeaker: Announcement <!here>: Upcoming Sessions :date:
Hey team!
We are excited to share the lineup of insightful and engaging sessions scheduled for the month of July. Please mark your calendars and make sure to attend these informative sessions:
:small_blue_diamond: July 9th Session: To be Conducted by <@U04NARS71G9> on Slack Productivity 
:small_blue_diamond: July 11th Session: To be conducted by <@U04HJT19EAD> on Green Coding.
:small_blue_diamond: July 18th Session: To be conducted by <@U05GN7RS1D1> on Fully Homomorphic Encryption.
:small_blue_diamond: July 25th Session: To be conducted by <@U04HJT1B5EV> on Best Coding Practices.
<@U05SY0JVBL6> has joined the channel
<@U06MYFKMV9U> has joined the channel
<@U05GN7RS1D1> has joined the channel


--- Messages from #naoris-swarm-ai-pipeline-health ---
UAT Topology Check Alert at 2025-04-29T11:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.29
     Doc Count: 75040
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-29T09:01:34Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.29
     Doc Count: 60696
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-29T07:01:46Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.29
     Doc Count: 48032
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-29T05:01:34Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.29
     Doc Count: 34521
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
*STAG OSS Disk Usage Notification at 2025-04-29T04:13:22Z*

:white_check_mark: *Good Health* *Node: 0c5ce918a825dd60ddbb4ffe1593d30f*
:floppy_disk: *Used:* 63.1 GB (12.83%)
:large_green_circle: *Free:* 428.7 GB
*Data Warehouse Disk Usage Notification at 2025-04-29T04:13:05Z*

:computer: *Disk Usage is Normal!* :computer:
:floppy_disk: *Used:* 80 GB (55.54%)
:octagonal_sign: *Available:* 64 GB

   *Host:* ip-172-31-13-207 (3.14.143.45)
UAT Topology Check Alert at 2025-04-29T03:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.29
     Doc Count: 20810
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-29T01:01:45Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.29
     Doc Count: 6327
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T23:01:40Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_nw_es_index_2025.04.28
     Doc Count: 15282
     Kafka Hit Count: 7369

  2. nao_pm_ac_es_index_2025.04.28
     Doc Count: 123836
     Kafka Hit Count: 100524

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T21:01:39Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_nw_es_index_2025.04.28
     Doc Count: 15282
     Kafka Hit Count: 7369

  2. nao_pm_ac_es_index_2025.04.28
     Doc Count: 110738
     Kafka Hit Count: 100524

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T19:01:46Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_nw_es_index_2025.04.28
     Doc Count: 13231
     Kafka Hit Count: 5957

  2. nao_pm_ac_es_index_2025.04.28
     Doc Count: 97736
     Kafka Hit Count: 82865

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T17:01:41Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_nw_es_index_2025.04.28
     Doc Count: 11396
     Kafka Hit Count: 4524

  2. nao_pm_ac_es_index_2025.04.28
     Doc Count: 84502
     Kafka Hit Count: 62654

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T15:01:38Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_nw_es_index_2025.04.28
     Doc Count: 3567
     Kafka Hit Count: 3244

  2. nao_pm_ac_es_index_2025.04.28
     Doc Count: 71189
     Kafka Hit Count: 43184

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T13:01:44Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_nw_es_index_2025.04.28
     Doc Count: 2305
     Kafka Hit Count: 1940

  2. nao_pm_ac_es_index_2025.04.28
     Doc Count: 57909
     Kafka Hit Count: 24515

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T11:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.28
     Doc Count: 48551
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T09:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.28
     Doc Count: 48551
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T07:01:46Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.28
     Doc Count: 48551
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T05:01:44Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.28
     Doc Count: 35804
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
*STAG OSS Disk Usage Notification at 2025-04-28T04:13:21Z*

:white_check_mark: *Good Health* *Node: 0c5ce918a825dd60ddbb4ffe1593d30f*
:floppy_disk: *Used:* 63.1 GB (12.83%)
:large_green_circle: *Free:* 428.7 GB
*Data Warehouse Disk Usage Notification at 2025-04-28T04:13:04Z*

:computer: *Disk Usage is Normal!* :computer:
:floppy_disk: *Used:* 82 GB (56.81%)
:octagonal_sign: *Available:* 62 GB

   *Host:* ip-172-31-13-207 (3.14.143.45)
UAT Topology Check Alert at 2025-04-28T03:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.28
     Doc Count: 21047
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-28T01:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.28
     Doc Count: 7558
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T23:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 170923
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T21:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 157611
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T19:01:43Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 143362
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T17:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 129036
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T15:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 115989
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T13:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 101479
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T11:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 86064
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T09:01:50Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 70539
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T07:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 54786
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T05:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 38581
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T03:01:46Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 23233
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-27T01:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.27
     Doc Count: 7719
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T23:01:41Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 176190
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T21:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 161383
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T19:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 147145
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T17:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 131082
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T15:01:37Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 115224
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T13:01:37Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 99540
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T11:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 83475
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T09:01:36Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 67342
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T07:01:45Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 51693
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T05:01:37Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 37311
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T03:02:16Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 23058
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-26T01:01:35Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.26
     Doc Count: 7652
     Kafka Hit Count: 0

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-25T23:01:40Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.25
     Doc Count: 167194
     Kafka Hit Count: 37248

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-25T21:01:38Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.25
     Doc Count: 150709
     Kafka Hit Count: 37248

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-25T19:01:40Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.25
     Doc Count: 134215
     Kafka Hit Count: 37248

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.
UAT Topology Check Alert at 2025-04-25T17:01:47Z:

The following Topologies have an ES count and Kafka hit count difference greater than 80:

  1. nao_pm_ac_es_index_2025.04.25
     Doc Count: 118883
     Kafka Hit Count: 37248

<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39> Please check and take necessary actions.


--- Messages from #dtp-peoplepulse-announcement ---
Abhay Malviya has logged off.
Akshay Gupta is Online.
Naveen Sharma is Online.
Aman Pandey is Online.
Saurabh Sharma is Online.
```List of employees who haven't logged in for 2025-04-29
No. | Name                   | Leave Applied
----|------------------------|--------------
1   | Akshay Gupta           | No Leave Applied
2   | Aman Pandey            | No Leave Applied
3   | Ankit Maindola         | Planned Leave 
4   | Anshul Semwal          | Planned Leave 
5   | Naveen Sharma          | No Leave Applied
6   | Pourush Gupta          | No Leave Applied
7   | Prakhar Srivastava     | No Leave Applied
8   | Puneet Nayal           | No Leave Applied
9   | Saurabh Sharma         | No Leave Applied
```
Pravesh Sharma is Online.
Alkesh Kumar Singh is Online.
Aayush Bhargava is Online.
Hritik kumar is Online.
Krishanu Ghosh is Online.
Atul Tamta is Online.
Priyanshu Sachan is Online.
Milind Pal Singh Tanwar is Online.
Vasundhara Goel is Online.
Sumit Kumar Sharma is Online.
Manas Kapoor is Online.
Divya Jain is Online.
Prince Kumar is Online.
Sankalp Sachan is Online.
Prerna Singh is Online.
Amit Kumar is Online.
Sayam Monga is Online.
Kartikey Saraswat is Online.
Ritesh Kumar Singh is Online.
Vishal Kaushal is Online.
Naman Jain is Online.
Tanisha Jain is Online.
Kanishka Jain is Online.
Animesh Jain is Online.
Harsh Saurav is Online.
Yash Garg is Online.
Khushboo Aggarwal is Online.
Yash Jain is Online.
Vishakha Bansal is Online.
Swati Taheem is Online.
Shivam Nayak is Online.
Deepak Sharma is Online.
Ayush Chamola is Online.
Siddhartha Mishra is Online.
Varsha Jyanth is Online.
Ujjawal Sanadhya is Online.
Akash Sahoo is Online.
Shubham Bisht is Online.
Vivek Kumar is Online.
Aanchal Aggarwal is Online.
Mandeep Shishodia is Online.
Malikashree Mahadevi Singh is Online.
Anshul Chamoli is Online.
Sandeep Gaur is Online.


--- Messages from #naoris-testnet-srv-health ---
ack
NP testnet Warning: Disk usage is high! Current usage: 82.6% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 82.5% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 82.3% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 82.3% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 82.2% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 82.1% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 82.0% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.9% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.8% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.7% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.6% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.5% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.5% for Node : 3.98.55.234
ack
NP testnet Warning: Memory usage is high! RAM: 87.2%, Swap: 100.0% for Node: 54.225.175.168
Informed <@U04HVUVP5CG> sir
ack
NP testnet Warning: Memory usage is high! RAM: 86.1%, Swap: 97.3% for Node: 54.225.175.168
ack
NP testnet Warning: Disk usage is high! Current usage: 81.5% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.4% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.3% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.2% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.1% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.0% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 81.0% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 80.9% for Node : 3.98.55.234
ack
NP testnet Warning: Disk usage is high! Current usage: 80.8% for Node : 3.98.55.234
ack


--- Messages from #naoris-congo-siem-pipeline-health ---
archived the channel
<!here> I am archivinng this channel, as no more data will come on this
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
Ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
Ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
Ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>
ack
:warning: No data found in `*wineventlog*2025.03*`. Please check!
:warning: No data found in `*linux*2025.03*`. Please check!
<@U04GZL76PNJ> <@U022UG2LXEZ> <@UF8TCND39>


--- Messages from #naoris-bdo-sink-pipeline-health ---
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
:white_check_mark: Latest data is present in `*wineventlog*2025.*`. All OK!!
<@U04HJT17AKB> <@U022UG2LXEZ> <@UF8TCND39>
ack
